{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "508ed619-1a65-4004-a731-43c563f1c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 加載數據的函數\n",
    "def load_treebank_splits(datadir):\n",
    "    def load_split(subdirs):\n",
    "        sentences = []\n",
    "        for subdir in subdirs:\n",
    "            path = os.path.join(datadir, subdir)\n",
    "            if not os.path.exists(path):\n",
    "                print(f\"Directory {path} does not exist!\")\n",
    "                continue\n",
    "            for file in os.listdir(path):\n",
    "                if file.endswith('.pos'):\n",
    "                    sentences.extend(load_pos_file(os.path.join(path, file)))\n",
    "        return sentences\n",
    "\n",
    "    train = load_split([f\"{i:02d}\" for i in range(0, 19)])  # Train: Folders 00-18\n",
    "    dev = load_split([f\"{i:02d}\" for i in range(19, 22)])   # Dev: Folders 19-21\n",
    "    test = load_split([f\"{i:02d}\" for i in range(22, 25)])  # Test: Folders 22-24\n",
    "\n",
    "    return train, dev, test\n",
    "\n",
    "def load_pos_file(filepath):\n",
    "    sentences = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        sentence = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(\"=\"):  # Skip empty lines and headers\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            for part in parts:\n",
    "                if \"/\" in part:\n",
    "                    word, tag = part.rsplit(\"/\", 1)\n",
    "                    sentence.append((word, tag))\n",
    "            if line.endswith(\".\"):\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46f152f6-f33a-410d-9004-d769bd336b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 HMM 模型\n",
    "transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "state_counts = defaultdict(int)\n",
    "\n",
    "def build_hmm(data):\n",
    "    for sentence in data:\n",
    "        prev_tag = \"<START>\"\n",
    "        for word, tag in sentence:\n",
    "            transition_counts[prev_tag][tag] += 1\n",
    "            emission_counts[tag][word] += 1\n",
    "            state_counts[prev_tag] += 1\n",
    "            state_counts[tag] += 1\n",
    "            prev_tag = tag\n",
    "        transition_counts[prev_tag][\"<STOP>\"] += 1\n",
    "        state_counts[prev_tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82e77545-c113-42c2-9c9d-ecd1e5b6da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(transition_counts, emission_counts, state_counts, alpha=1.0):\n",
    "    transition_probs = defaultdict(lambda: defaultdict(lambda: float('-inf')))\n",
    "    emission_probs = defaultdict(lambda: defaultdict(lambda: float('-inf')))\n",
    "\n",
    "    # 計算轉移概率\n",
    "    for prev_tag in transition_counts:\n",
    "        total = sum(transition_counts[prev_tag].values()) + alpha * len(state_counts)\n",
    "        for curr_tag in state_counts:\n",
    "            transition_probs[prev_tag][curr_tag] = \\\n",
    "                (transition_counts[prev_tag].get(curr_tag, 0) + alpha) / total\n",
    "\n",
    "    for tag in emission_counts:\n",
    "        total = sum(emission_counts[tag].values()) + alpha * len(emission_counts)\n",
    "        for word in emission_counts[tag]:\n",
    "            emission_probs[tag][word] = (emission_counts[tag][word] + alpha) / total\n",
    "        # 添加 <UNK>\n",
    "        emission_probs[tag][\"<UNK>\"] = alpha / total\n",
    "\n",
    "    # 確保每個標籤都有 <UNK>\n",
    "    for tag in state_counts:\n",
    "        if \"<UNK>\" not in emission_probs[tag]:\n",
    "            total = sum(emission_counts[tag].values()) + alpha * len(emission_counts)\n",
    "            emission_probs[tag][\"<UNK>\"] = alpha / total\n",
    "\n",
    "    return transition_probs, emission_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f3d4c05-0d59-4d46-b2e4-897cc267edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sentence, transition_probs, emission_probs, state_counts):\n",
    "    n = len(sentence)\n",
    "    states = list(state_counts.keys())\n",
    "    dp = [{} for _ in range(n)]  # DP table\n",
    "    backpointer = [{} for _ in range(n)]  # Backpointer table\n",
    "\n",
    "    # 初始狀態\n",
    "    for state in states:\n",
    "        dp[0][state] = (\n",
    "            transition_probs[\"<START>\"].get(state, 1e-6) * \n",
    "            emission_probs[state].get(sentence[0], emission_probs[state].get(\"<UNK>\", 1e-6))\n",
    "        )\n",
    "        backpointer[0][state] = \"<START>\"\n",
    "\n",
    "    # 動態規劃\n",
    "    for t in range(1, n):\n",
    "        for state in states:\n",
    "            max_prob, best_prev_state = max(\n",
    "                (\n",
    "                    dp[t - 1][prev_state] *\n",
    "                    transition_probs[prev_state].get(state, 1e-6) *\n",
    "                    emission_probs[state].get(sentence[t], emission_probs[state].get(\"<UNK>\", 1e-6)),\n",
    "                    prev_state\n",
    "                )\n",
    "                for prev_state in states\n",
    "            )\n",
    "            dp[t][state] = max_prob\n",
    "            backpointer[t][state] = best_prev_state\n",
    "\n",
    "    # 終止狀態\n",
    "    max_prob, best_final_state = max(\n",
    "        (dp[n - 1][state] * transition_probs[state].get(\"<STOP>\", 1e-6), state)\n",
    "        for state in states\n",
    "    )\n",
    "\n",
    "    # 回溯\n",
    "    best_path = []\n",
    "    current_state = best_final_state\n",
    "    for t in range(n - 1, -1, -1):\n",
    "        best_path.append(current_state)\n",
    "        current_state = backpointer[t][current_state]\n",
    "    best_path.reverse()\n",
    "\n",
    "    return best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3ca5da8-8e36-4f25-b19c-9d4acc938e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估模型性能\n",
    "def evaluate(test_set, predictions):\n",
    "    y_true, y_pred = [], []\n",
    "    for sentence, pred in zip(test_set, predictions):\n",
    "        y_true.extend([tag for _, tag in sentence])\n",
    "        y_pred.extend(pred)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61af7b41-5626-461b-8d1f-d01512e947b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sentences: 40138\n",
      "Dev sentences: 6120\n",
      "Test sentences: 7029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       0.25      1.00      0.40        22\n",
      "           $       0.87      0.99      0.92      1138\n",
      "          ''       0.84      0.97      0.90      1380\n",
      "           (       0.86      0.85      0.86       239\n",
      "           )       0.72      0.90      0.80       240\n",
      "           ,       1.00      0.97      0.98      9041\n",
      "           .       1.00      1.00      1.00      7035\n",
      "           :       0.97      0.83      0.89       959\n",
      "          CC       1.00      0.85      0.92      4287\n",
      "          CD       0.99      0.79      0.88      6000\n",
      "          DT       0.99      0.94      0.97     14937\n",
      "          EX       0.35      0.98      0.51       174\n",
      "          FW       0.00      0.70      0.00        37\n",
      "          IN       0.97      0.86      0.91     18138\n",
      "       IN|RB       0.00      0.00      0.00         0\n",
      "          JJ       0.89      0.64      0.75     10695\n",
      "         JJR       0.69      0.72      0.70       581\n",
      "     JJR|RBR       0.00      0.00      0.00         4\n",
      "         JJS       0.83      0.87      0.85       371\n",
      "       JJ|IN       0.00      0.00      0.00         1\n",
      "      JJ|JJR       0.00      0.00      0.00         0\n",
      "       JJ|NN       0.00      0.00      0.00         0\n",
      "          LS       0.03      0.53      0.05        15\n",
      "          MD       0.95      0.93      0.94      1673\n",
      "          NN       0.97      0.76      0.86     23438\n",
      "         NNP       0.98      0.58      0.73     17185\n",
      "        NNPS       0.14      0.33      0.20       238\n",
      "         NNS       0.98      0.71      0.82     10684\n",
      "      NNS|NN       0.00      0.00      0.00         0\n",
      "       NN|JJ       0.00      0.00      0.00         0\n",
      "      NN|NNS       0.00      0.00      0.00         0\n",
      "      NN|POS       0.00      0.00      0.00         0\n",
      "         PDT       0.15      0.94      0.26        66\n",
      "         POS       0.93      0.92      0.92      1634\n",
      "         PRP       0.94      0.94      0.94      2929\n",
      "        PRP$       0.82      0.88      0.85      1432\n",
      "          RB       0.90      0.70      0.79      5850\n",
      "         RBR       0.69      0.61      0.65       382\n",
      "     RBR|JJR       0.00      0.00      0.00         2\n",
      "         RBS       0.25      0.79      0.38        87\n",
      "       RB|JJ       0.00      0.00      0.00         2\n",
      "          RP       0.30      0.69      0.42       355\n",
      "         SYM       0.04      0.64      0.08        11\n",
      "          TO       1.00      0.95      0.97      3893\n",
      "          UH       0.02      0.85      0.04        20\n",
      "          VB       0.92      0.87      0.89      4748\n",
      "         VBD       0.97      0.76      0.85      5867\n",
      "         VBG       0.94      0.56      0.70      2590\n",
      "      VBG|JJ       0.00      0.00      0.00         0\n",
      "      VBG|NN       0.00      0.00      0.00         1\n",
      "   VBG|NN|JJ       0.00      0.00      0.00         0\n",
      "         VBN       0.83      0.69      0.75      3573\n",
      "      VBN|JJ       0.00      0.00      0.00         2\n",
      "         VBP       0.91      0.75      0.82      2206\n",
      "     VBP|VBD       0.00      0.00      0.00         0\n",
      "         VBZ       0.97      0.82      0.89      3603\n",
      "       VB|IN       0.00      0.00      0.00         0\n",
      "       VB|NN       0.00      0.00      0.00         0\n",
      "         WDT       0.72      0.87      0.79       772\n",
      "          WP       0.96      0.89      0.92       397\n",
      "         WP$       0.21      0.94      0.35        47\n",
      "         WRB       0.87      0.86      0.87       425\n",
      "          ``       0.84      0.96      0.90      1413\n",
      "\n",
      "    accuracy                           0.80    170819\n",
      "   macro avg       0.51      0.58      0.51    170819\n",
      "weighted avg       0.95      0.80      0.86    170819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 主程序\n",
    "datadir = r\"C:\\Users\\USER\\Downloads\\NLP-Courses\\NLP201\\Assignments\\HW3\\data\\penn-treeban3-wsj\\wsj\"\n",
    "train, dev, test = load_treebank_splits(datadir)\n",
    "\n",
    "# 使用部分資料集\n",
    "train = train  # 僅使用前 100 條訓練數據\n",
    "dev = dev      # 僅使用前 50 條開發數據\n",
    "test = test    # 僅使用前 50 條測試數據\n",
    "\n",
    "print(f\"Train sentences: {len(train)}\")\n",
    "print(f\"Dev sentences: {len(dev)}\")\n",
    "print(f\"Test sentences: {len(test)}\")\n",
    "\n",
    "# 計算轉移和發射計數\n",
    "transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "state_counts = defaultdict(int)\n",
    "\n",
    "for sentence in train:\n",
    "    prev_tag = \"<START>\"\n",
    "    for word, tag in sentence:\n",
    "        transition_counts[prev_tag][tag] += 1\n",
    "        emission_counts[tag][word] += 1\n",
    "        state_counts[tag] += 1\n",
    "        prev_tag = tag\n",
    "    transition_counts[prev_tag][\"<STOP>\"] += 1\n",
    "\n",
    "# 計算轉移和發射概率\n",
    "transition_probs, emission_probs = calculate_probabilities(\n",
    "    transition_counts, emission_counts, state_counts, alpha=1.0\n",
    ")\n",
    "\n",
    "# 測試 Viterbi\n",
    "test_sentences = [[word for word, tag in sentence] for sentence in test]\n",
    "predictions = []\n",
    "for i, sentence in enumerate(test_sentences):\n",
    "    try:\n",
    "        prediction = viterbi(sentence, transition_probs, emission_probs, state_counts)\n",
    "        predictions.append(prediction)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in sentence {i}: {sentence}\")\n",
    "        print(f\"Error: {e}\")\n",
    "        predictions.append([\"<UNK>\"] * len(sentence))\n",
    "\n",
    "# 評估模型\n",
    "evaluate(test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01c031-8cc2-4fa7-9bc6-218669534686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
