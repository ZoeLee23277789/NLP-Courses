{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec4a02f9-065a-4f4f-b35d-6e2200f04ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Id                           Title  Price         User_id  \\\n",
      "0  1882931173  Its Only Art If Its Well Hung!    NaN   AVCGYZL8FQQTD   \n",
      "1  0826414346        Dr. Seuss: American Icon    NaN  A30TK6U7DNS82R   \n",
      "2  0826414346        Dr. Seuss: American Icon    NaN  A3UH4UZ4RSVO82   \n",
      "3  0826414346        Dr. Seuss: American Icon    NaN  A2MVUWT453QH61   \n",
      "4  0826414346        Dr. Seuss: American Icon    NaN  A22X4XUPKF66MR   \n",
      "\n",
      "                          profileName review/helpfulness  review/score  \\\n",
      "0               Jim of Oz \"jim-of-oz\"                7/7           4.0   \n",
      "1                       Kevin Killian              10/10           5.0   \n",
      "2                        John Granger              10/11           5.0   \n",
      "3  Roy E. Perry \"amateur philosopher\"                7/7           4.0   \n",
      "4     D. H. Richards \"ninthwavestore\"                3/3           4.0   \n",
      "\n",
      "   review/time                                   review/summary  \\\n",
      "0    940636800           Nice collection of Julie Strain images   \n",
      "1   1095724800                                Really Enjoyed It   \n",
      "2   1078790400  Essential for every personal and Public Library   \n",
      "3   1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
      "4   1107993600                           Good academic overview   \n",
      "\n",
      "                                         review/text  label  \n",
      "0  This is only for Julie Strain fans. It's a col...      1  \n",
      "1  I don't care much for Dr. Seuss but after read...      1  \n",
      "2  If people become the books they read and if \"t...      1  \n",
      "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...      1  \n",
      "4  Philip Nel - Dr. Seuss: American IconThis is b...      1  \n",
      "   review/score  label\n",
      "0           4.0      1\n",
      "1           5.0      1\n",
      "2           5.0      1\n",
      "3           4.0      1\n",
      "4           4.0      1\n",
      "label\n",
      "1    2392959\n",
      "0     352746\n",
      "Name: count, dtype: int64\n",
      "訓練集大小: (2333849, 11)\n",
      "測試集大小: (411856, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取 CSV 檔案\n",
    "file_path = \"C:/Users/USER/Downloads/NLP-Courses/NLP220/Assignments/processed_books_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 檢視前五筆資料\n",
    "print(df.head())\n",
    "# 篩選只包含 1, 2, 4, 5 星評分的資料\n",
    "df_filtered = df[df['review/score'].isin([1, 2, 4, 5])]\n",
    "\n",
    "# 新增 'label' 欄位，根據評分來分類\n",
    "df_filtered['label'] = df_filtered['review/score'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "# 檢視結果\n",
    "print(df_filtered[['review/score', 'label']].head())\n",
    "# 檢查正向和負向評論的分布情況\n",
    "print(df_filtered['label'].value_counts())\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 分割資料集，85% 用於訓練，15% 用於測試\n",
    "train_data, test_data = train_test_split(df_filtered, test_size=0.15, random_state=42, stratify=df_filtered['label'])\n",
    "\n",
    "# 檢查分割後的資料大小\n",
    "print(\"訓練集大小:\", train_data.shape)\n",
    "\n",
    "print(\"測試集大小:\", test_data.shape)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 移除 'review/text' 欄位中為 NaN 的列\n",
    "train_data = train_data.dropna(subset=['review/text'])\n",
    "test_data = test_data.dropna(subset=['review/text'])\n",
    "vectorizer_count = CountVectorizer(stop_words='english', max_features=100)\n",
    "X_train_count = vectorizer_count.fit_transform(train_data['review/text'])\n",
    "X_test_count = vectorizer_count.transform(test_data['review/text'])\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(train_data['review/text'])\n",
    "X_test_tfidf = vectorizer_tfidf.transform(test_data['review/text'])\n",
    "train_data['combined_text'] = train_data['review/summary'] + \" \" + train_data['review/text']\n",
    "test_data['combined_text'] = test_data['review/summary'] + \" \" + test_data['review/text']\n",
    "# 填補 NaN 值\n",
    "train_data['combined_text'] = train_data['combined_text'].fillna('')\n",
    "test_data['combined_text'] = test_data['combined_text'].fillna('')\n",
    "\n",
    "# 使用 TfidfVectorizer 處理\n",
    "vectorizer_combined = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "X_train_combined = vectorizer_combined.fit_transform(train_data['combined_text'])\n",
    "X_test_combined = vectorizer_combined.transform(test_data['combined_text'])\n",
    "from joblib import parallel_backend\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "# 建立 SVC 模型\n",
    "svc_model_count = SVC(kernel='linear')  # 如果你使用非線性核如 'rbf'，計算會更慢\n",
    "svc_model_tfidf = SVC(kernel='linear')\n",
    "svc_model_combined = SVC(kernel='linear')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19565c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練與預測函數\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    # 訓練模型\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # 預測\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    # 計算評估指標\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, f1, cm, train_time, inference_time\n",
    "\n",
    "# 標籤資料\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "\n",
    "# 使用 joblib 進行多核並行運算\n",
    "with parallel_backend('threading', n_jobs=-1):  # 使用所有可用的 CPU 核心\n",
    "    # 訓練與評估 Count Vectorizer 特徵\n",
    "    acc_count, f1_count, cm_count, train_time_count, inference_time_count = train_and_evaluate(svc_model_count, X_train_count, X_test_count, y_train, y_test)\n",
    "\n",
    "    # 訓練與評估 Tfidf 特徵\n",
    "    acc_tfidf, f1_tfidf, cm_tfidf, train_time_tfidf, inference_time_tfidf = train_and_evaluate(svc_model_tfidf, X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "\n",
    "    # 訓練與評估 Combined 特徵\n",
    "    acc_combined, f1_combined, cm_combined, train_time_combined, inference_time_combined = train_and_evaluate(svc_model_combined, X_train_combined, X_test_combined, y_train, y_test)\n",
    "\n",
    "# 結果輸出\n",
    "print(\"Count Vectorizer - Accuracy: {:.4f}, F1: {:.4f}, Training time: {:.4f}s, Inference time: {:.4f}s\".format(acc_count, f1_count, train_time_count, inference_time_count))\n",
    "print(\"Tfidf Vectorizer - Accuracy: {:.4f}, F1: {:.4f}, Training time: {:.4f}s, Inference time: {:.4f}s\".format(acc_tfidf, f1_tfidf, train_time_tfidf, inference_time_tfidf))\n",
    "print(\"Combined Features - Accuracy: {:.4f}, F1: {:.4f}, Training time: {:.4f}s, Inference time: {:.4f}s\".format(acc_combined, f1_combined, train_time_combined, inference_time_combined))\n",
    "\n",
    "print(\"Confusion Matrix for Count Vectorizer:\\n\", cm_count)\n",
    "print(\"Confusion Matrix for Tfidf Vectorizer:\\n\", cm_tfidf)\n",
    "print(\"Confusion Matrix for Combined Features:\\n\", cm_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9350ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Naive Bayes Accuracy: 0.8747180439717862\n",
      "Sklearn Naive Bayes F1 Score: 0.7320381100061164\n",
      "Sklearn Naive Bayes Confusion Matrix:\n",
      "[[ 29863  23049]\n",
      " [ 28549 330394]]\n",
      "\n",
      "My Naive Bayes Accuracy: 0.8747059037768147\n",
      "My Naive Bayes F1 Score: 0.7320060502466966\n",
      "My Naive Bayes Confusion Matrix:\n",
      "[[ 29859  23053]\n",
      " [ 28550 330393]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 讀取 CSV 檔案\n",
    "file_path = \"C:/Users/USER/Downloads/NLP-Courses/NLP220/Assignments/processed_books_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 篩選只包含 1, 2, 4, 5 星評分的資料\n",
    "df_filtered = df[df['review/score'].isin([1, 2, 4, 5])]\n",
    "\n",
    "# 新增 'label' 欄位，根據評分來分類：4或5星為正面(1)，1或2星為負面(0)\n",
    "df_filtered['label'] = df_filtered['review/score'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "# 移除 'review/text' 欄位中為 NaN 的列\n",
    "df_filtered = df_filtered.dropna(subset=['review/text'])\n",
    "\n",
    "# 分割資料集，85% 用於訓練，15% 用於測試\n",
    "train_data, test_data = train_test_split(df_filtered, test_size=0.15, random_state=42, stratify=df_filtered['label'])\n",
    "\n",
    "# 使用 CountVectorizer 進行文本轉換\n",
    "vectorizer_count = CountVectorizer(stop_words='english', max_features=1000)\n",
    "X_train_count = vectorizer_count.fit_transform(train_data['review/text'])\n",
    "X_test_count = vectorizer_count.transform(test_data['review/text'])\n",
    "\n",
    "# 自定義的 Naive Bayes 分類器\n",
    "class MyNaiveBayes:\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "        self.class_priors = None\n",
    "        self.feature_log_prob = None\n",
    "        self.classes = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # 取得唯一的類別標籤\n",
    "        self.classes = np.unique(y)\n",
    "        # 計算每個類別的先驗機率 P(y)\n",
    "        self.class_priors = np.zeros(len(self.classes))\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            self.class_priors[idx] = np.sum(y == c) / len(y)\n",
    "        \n",
    "        # 計算條件機率 P(x|y) 並使用拉普拉斯平滑\n",
    "        feature_count = np.zeros((len(self.classes), X.shape[1]))\n",
    "        for idx, c in enumerate(self.classes):\n",
    "            feature_count[idx, :] = np.sum(X[y == c], axis=0)\n",
    "        \n",
    "        # 使用 alpha 進行平滑\n",
    "        self.feature_log_prob = np.log((feature_count + self.alpha) / \n",
    "                                       (feature_count.sum(axis=1, keepdims=True) + self.alpha * X.shape[1]))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        log_probs = np.log(self.class_priors) + X @ self.feature_log_prob.T\n",
    "        return self.classes[np.argmax(log_probs, axis=1)]\n",
    "\n",
    "\n",
    "# 使用 sklearn 的 MultinomialNB 模型\n",
    "sklearn_nb = MultinomialNB()\n",
    "sklearn_nb.fit(X_train_count, train_data['label'])\n",
    "sklearn_preds = sklearn_nb.predict(X_test_count)\n",
    "\n",
    "# 使用自定義 Naive Bayes 模型\n",
    "my_nb = MyNaiveBayes()\n",
    "my_nb.fit(X_train_count.toarray(), train_data['label'].values)\n",
    "my_preds = my_nb.predict(X_test_count.toarray())\n",
    "\n",
    "# 計算並顯示結果\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "    print(f\"{model_name} F1 Score: {f1}\")\n",
    "    print(f\"{model_name} Confusion Matrix:\\n{cm}\\n\")\n",
    "\n",
    "# 評估 sklearn 和自定義模型的表現\n",
    "evaluate_model(test_data['label'], sklearn_preds, \"Sklearn Naive Bayes\")\n",
    "evaluate_model(test_data['label'], my_preds, \"My Naive Bayes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ca054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56510605",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1536368558.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Sklearn Naive Bayes Accuracy: 0.8747180439717862\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Sklearn Naive Bayes Accuracy: 0.8747180439717862\n",
    "Sklearn Naive Bayes F1 Score: 0.7320381100061164\n",
    "Sklearn Naive Bayes Confusion Matrix:\n",
    "[[ 29863  23049]\n",
    " [ 28549 330394]]\n",
    "\n",
    "My Naive Bayes Accuracy: 0.8747180439717862\n",
    "My Naive Bayes F1 Score: 0.7320381100061164\n",
    "My Naive Bayes Confusion Matrix:\n",
    "[[ 29863  23049]\n",
    " [ 28549 330394]]\n",
    "======================================================\n",
    "Sklearn Naive Bayes Accuracy: 0.8747180439717862\n",
    "Sklearn Naive Bayes F1 Score: 0.7320381100061164\n",
    "Sklearn Naive Bayes Confusion Matrix:\n",
    "[[ 29863  23049]\n",
    " [ 28549 330394]]\n",
    "\n",
    "My Naive Bayes Accuracy: 0.8747204720107805\n",
    "My Naive Bayes F1 Score: 0.7320412723898135\n",
    "My Naive Bayes Confusion Matrix:\n",
    "[[ 29863  23049]\n",
    " [ 28548 330395]]\n",
    "=========================================================\n",
    "Sklearn Naive Bayes Accuracy: 0.8747180439717862\n",
    "Sklearn Naive Bayes F1 Score: 0.7320381100061164\n",
    "Sklearn Naive Bayes Confusion Matrix:\n",
    "[[ 29863  23049]\n",
    " [ 28549 330394]]\n",
    "\n",
    "My Naive Bayes Accuracy: 0.8747204720107805\n",
    "My Naive Bayes F1 Score: 0.7320412723898135\n",
    "My Naive Bayes Confusion Matrix:\n",
    "[[ 29863  23049]\n",
    " [ 28548 330395]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071a3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
