{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a540b7-d50b-4871-872d-4008e0e4c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 定義根目錄，便於動態構建路徑\n",
    "base_dir = os.path.join(\".\", \"aclImdb_v1\", \"aclImdb\")\n",
    "\n",
    "def load_reviews(directory, label):\n",
    "    reviews = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            review_text = file.read()\n",
    "            # 文件名格式為 [id]_[rating].txt，例如 200_8.txt\n",
    "            id, rating = file_name.split('_')\n",
    "            rating = rating.split('.')[0]  # 去掉文件擴展名\n",
    "            reviews.append([id, rating, review_text, label])\n",
    "    return reviews\n",
    "\n",
    "# 讀取訓練集正向和負向評論，使用 os.path.join 動態構建路徑\n",
    "train_pos_reviews = load_reviews(os.path.join(base_dir, \"train\", \"pos\"), 1)  # label為1，代表正向\n",
    "train_neg_reviews = load_reviews(os.path.join(base_dir, \"train\", \"neg\"), 0)  # label為0，代表負向\n",
    "# 合併訓練數據\n",
    "train_reviews = train_pos_reviews + train_neg_reviews\n",
    "# 創建 DataFrame 並保存為 CSV\n",
    "train_df = pd.DataFrame(train_reviews, columns=['id', 'rating', 'review_text', 'label'])\n",
    "# 保存訓練集 CSV 檔案\n",
    "train_df.to_csv(os.path.join(base_dir, \"train\", \"train_reviews.csv\"), index=False)\n",
    "print(\"Get the train_reviews.csv\")\n",
    "\n",
    "# 如果你有測試集，可以用同樣的方式處理測試集正向和負向評論\n",
    "test_pos_reviews = load_reviews(os.path.join(base_dir, \"test\", \"pos\"), 1)\n",
    "test_neg_reviews = load_reviews(os.path.join(base_dir, \"test\", \"neg\"), 0)\n",
    "# 合併測試數據\n",
    "test_reviews = test_pos_reviews + test_neg_reviews\n",
    "test_df = pd.DataFrame(test_reviews, columns=['id', 'rating', 'review_text', 'label'])\n",
    "test_df.to_csv(os.path.join(base_dir, \"test\", \"test_reviews.csv\"), index=False)\n",
    "\n",
    "# 加載訓練和測試數據\n",
    "train_df = pd.read_csv(os.path.join(base_dir, \"train\", \"train_reviews.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(base_dir, \"test\", \"test_reviews.csv\"))\n",
    "\n",
    "# 使用 train_test_split 將訓練數據進一步拆分為訓練集和驗證集\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df['review_text'], train_df['label'], test_size=0.1, random_state=42)\n",
    "\n",
    "# 使用 TfidfVectorizer 提取 n-gram 特徵\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')  # Example: bigrams, remove stopwords\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(test_df['review_text'])\n",
    "\n",
    "print(\"==================================================================================\")\n",
    "\n",
    "# Get the best hyperparameters form Optuna\n",
    "best_params = {\n",
    "    \"Naive Bayes\": {'alpha': 0.05450760213833489},\n",
    "    \"Logistic Regression\": {'C': 89.67647856745852, 'solver': 'saga', 'max_iter': 1000},\n",
    "    \"Decision Tree\": {'max_depth': 20, 'min_samples_split': 3},\n",
    "    \"Random Forest\": {'n_estimators': 189, 'max_depth': 18, 'min_samples_split': 6},\n",
    "    \"KNN\": {'n_neighbors': 7}\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(**best_params[\"Naive Bayes\"]),\n",
    "    \"Logistic Regression\": LogisticRegression(**best_params[\"Logistic Regression\"]),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(**best_params[\"Decision Tree\"]),\n",
    "    \"Random Forest\": RandomForestClassifier(**best_params[\"Random Forest\"]),\n",
    "    \"KNN\": KNeighborsClassifier(**best_params[\"KNN\"])\n",
    "}\n",
    "print(\"==================================================================================\")\n",
    "# 用於保存模型驗證集的準確率和最好的模型名稱\n",
    "best_model_name = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "# 訓練每個模型，並輸出驗證集上的準確率\n",
    "for model_name, model in models.items():\n",
    "    print(\"model_name = \" ,model_name)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    val_predictions = model.predict(X_val_tfidf)\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    print(f\"{model_name} Validation Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    # 保存驗證集上最好的模型\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_model_name = model_name\n",
    "\n",
    "# 使用驗證集表現最好的模型在測試集上進行評估\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "best_model = models[best_model_name]\n",
    "test_predictions = best_model.predict(X_test_tfidf)\n",
    "test_accuracy = accuracy_score(test_df['label'], test_predictions)\n",
    "print(f\"{best_model_name} Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "print(\"==================================================================================\")\n",
    "\n",
    "# # Find the best hyperparameters using Optuna\n",
    "# # 定义每个模型的超参数优化\n",
    "# print(\"定义每个模型的超参数优化\")\n",
    "# # 6. KNN\n",
    "# def optimize_knn(trial):\n",
    "#     n_neighbors = trial.suggest_int('n_neighbors', 1, 50)\n",
    "#     model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "#     model.fit(X_train_tfidf, y_train)\n",
    "#     val_predictions = model.predict(X_val_tfidf)\n",
    "#     return accuracy_score(y_val, val_predictions)\n",
    "\n",
    "\n",
    "# # 1. Naive Bayes\n",
    "# def optimize_naive_bayes(trial):\n",
    "#     alpha = trial.suggest_loguniform('alpha', 1e-3, 1e1)\n",
    "#     model = MultinomialNB(alpha=alpha)\n",
    "#     model.fit(X_train_tfidf, y_train)\n",
    "#     val_predictions = model.predict(X_val_tfidf)\n",
    "#     return accuracy_score(y_val, val_predictions)\n",
    "\n",
    "# # 2. SVM\n",
    "# def optimize_svm(trial):\n",
    "#     C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
    "#     kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
    "#     model = SVC(C=C, kernel=kernel)\n",
    "#     model.fit(X_train_tfidf, y_train)\n",
    "#     val_predictions = model.predict(X_val_tfidf)\n",
    "#     return accuracy_score(y_val, val_predictions)\n",
    "\n",
    "# # 3. Logistic Regression\n",
    "# def optimize_logistic_regression(trial):\n",
    "#     C = trial.suggest_loguniform('C', 1e-4, 1e2)\n",
    "#     solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "#     model = LogisticRegression(C=C, solver=solver, max_iter=1000)\n",
    "#     model.fit(X_train_tfidf, y_train)\n",
    "#     val_predictions = model.predict(X_val_tfidf)\n",
    "#     return accuracy_score(y_val, val_predictions)\n",
    "\n",
    "# # 4. Decision Tree\n",
    "# def optimize_decision_tree(trial):\n",
    "#     max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "#     min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "#     model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "#     model.fit(X_train_tfidf, y_train)\n",
    "#     val_predictions = model.predict(X_val_tfidf)\n",
    "#     return accuracy_score(y_val, val_predictions)\n",
    "\n",
    "# # 5. Random Forest\n",
    "# def optimize_random_forest(trial):\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "#     max_depth = trial.suggest_int('max_depth', 2, 20)\n",
    "#     min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "#     model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "#     model.fit(X_train_tfidf, y_train)\n",
    "#     val_predictions = model.predict(X_val_tfidf)\n",
    "#     return accuracy_score(y_val, val_predictions)\n",
    "\n",
    "# # 优化每个模型的超参数\n",
    "# models = {\n",
    "#     \"Naive Bayes\": optimize_naive_bayes,\n",
    "#     \"Logistic Regression\": optimize_logistic_regression,\n",
    "#     \"Decision Tree\": optimize_decision_tree,\n",
    "#     \"Random Forest\": optimize_random_forest,\n",
    "#     \"KNN\": optimize_knn,\n",
    "# }\n",
    "\n",
    "# best_models = {}\n",
    "# for model_name, objective in models.items():\n",
    "#     print(f\"Optimizing {model_name}...\")\n",
    "#     study = optuna.create_study(direction='maximize')\n",
    "#     study.optimize(objective, n_trials=50)\n",
    "#     print(f\"Best {model_name} parameters: {study.best_trial.params}\")\n",
    "#     print(f\"Best validation accuracy: {study.best_trial.value}\")\n",
    "#     best_models[model_name] = study.best_trial.params\n",
    "\n",
    "# # 在测试集上使用每个模型的最佳超参数\n",
    "# for model_name, best_params in best_models.items():\n",
    "#     print(f\"\\nTesting best {model_name} model on test set:\")\n",
    "    \n",
    "#     if model_name == \"Naive Bayes\":\n",
    "#         model = MultinomialNB(**best_params)\n",
    "#     elif model_name == \"Logistic Regression\":\n",
    "#         model = LogisticRegression(**best_params)\n",
    "#     elif model_name == \"Decision Tree\":\n",
    "#         model = DecisionTreeClassifier(**best_params)\n",
    "#     elif model_name == \"Random Forest\":\n",
    "#         model = RandomForestClassifier(**best_params)\n",
    "#     elif model_name == \"KNN\":\n",
    "#         model = KNN(**best_params)\n",
    "#     model.fit(X_train_tfidf, y_train)\n",
    "#     test_predictions = model.predict(X_test_tfidf)\n",
    "#     test_accuracy = accuracy_score(test_df['label'], test_predictions)\n",
    "#     print(f\"{model_name} Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "print(\"======================================= Finish all the Part B ===========================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
