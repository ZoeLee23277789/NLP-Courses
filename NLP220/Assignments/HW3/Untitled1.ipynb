{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a830d4-0049-4fbe-8cf6-a058e75f7f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Validation Micro F1 Score: 0.7026\n",
      "Naive Bayes Validation Macro F1 Score: 0.0299\n",
      "Naive Bayes Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.55      0.16      0.25      1150\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.00      0.00      0.00       238\n",
      "          10       0.00      0.00      0.00       103\n",
      "          11       0.89      0.92      0.91      4526\n",
      "          12       0.00      0.00      0.00        30\n",
      "          13       0.00      0.00      0.00        23\n",
      "          14       0.00      0.00      0.00        49\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       0.00      0.00      0.00        32\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00        90\n",
      "          21       0.00      0.00      0.00        22\n",
      "          22       0.00      0.00      0.00        48\n",
      "          23       0.00      0.00      0.00        59\n",
      "          24       0.00      0.00      0.00        41\n",
      "          25       0.85      0.85      0.85      4393\n",
      "          26       0.00      0.00      0.00         9\n",
      "          27       0.00      0.00      0.00        55\n",
      "          28       0.00      0.00      0.00        77\n",
      "          29       0.00      0.00      0.00        22\n",
      "          30       0.00      0.00      0.00       187\n",
      "          31       0.00      0.00      0.00        20\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         7\n",
      "          34       0.00      0.00      0.00       305\n",
      "          35       0.00      0.00      0.00         4\n",
      "          36       0.00      0.00      0.00        26\n",
      "          37       0.00      0.00      0.00        15\n",
      "          38       1.00      0.01      0.02       111\n",
      "          39       0.00      0.00      0.00        77\n",
      "          40       0.00      0.00      0.00         4\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00        28\n",
      "          43       0.00      0.00      0.00       354\n",
      "          44       0.00      0.00      0.00        85\n",
      "          45       0.00      0.00      0.00        57\n",
      "          46       0.00      0.00      0.00         3\n",
      "          47       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         8\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00        12\n",
      "          52       0.00      0.00      0.00         4\n",
      "          53       0.00      0.00      0.00        41\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       1.00      0.01      0.02       120\n",
      "          56       0.00      0.00      0.00         9\n",
      "          57       0.00      0.00      0.00         4\n",
      "          58       0.00      0.00      0.00        22\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.00      0.00      0.00         8\n",
      "          61       0.00      0.00      0.00         6\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00        19\n",
      "          64       0.00      0.00      0.00        18\n",
      "          65       0.00      0.00      0.00        15\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         3\n",
      "          68       0.00      0.00      0.00        10\n",
      "          69       0.00      0.00      0.00         3\n",
      "          70       0.00      0.00      0.00         8\n",
      "          71       0.00      0.00      0.00        11\n",
      "          72       0.00      0.00      0.00         9\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00        25\n",
      "          75       0.00      0.00      0.00        47\n",
      "          76       0.00      0.00      0.00         6\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         7\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00         5\n",
      "          83       0.00      0.00      0.00        56\n",
      "          84       0.00      0.00      0.00        16\n",
      "          85       0.00      0.00      0.00        32\n",
      "          86       0.65      0.53      0.59      2354\n",
      "          87       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.82      0.61      0.70     15286\n",
      "   macro avg       0.06      0.03      0.03     15286\n",
      "weighted avg       0.66      0.61      0.62     15286\n",
      " samples avg       0.87      0.72      0.75     15286\n",
      "\n",
      "Progress: 20.00% complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Micro F1 Score: 0.7216\n",
      "Logistic Regression Validation Macro F1 Score: 0.0452\n",
      "Logistic Regression Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.58      0.15      0.24      1150\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.56      0.15      0.23       238\n",
      "          10       0.42      0.08      0.13       103\n",
      "          11       0.94      0.91      0.92      4526\n",
      "          12       0.00      0.00      0.00        30\n",
      "          13       0.00      0.00      0.00        23\n",
      "          14       0.00      0.00      0.00        49\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       0.00      0.00      0.00        32\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00        90\n",
      "          21       0.00      0.00      0.00        22\n",
      "          22       1.00      0.04      0.08        48\n",
      "          23       0.00      0.00      0.00        59\n",
      "          24       0.00      0.00      0.00        41\n",
      "          25       0.86      0.86      0.86      4393\n",
      "          26       0.00      0.00      0.00         9\n",
      "          27       0.69      0.20      0.31        55\n",
      "          28       0.00      0.00      0.00        77\n",
      "          29       0.00      0.00      0.00        22\n",
      "          30       0.33      0.01      0.01       187\n",
      "          31       0.00      0.00      0.00        20\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         7\n",
      "          34       0.61      0.08      0.13       305\n",
      "          35       0.00      0.00      0.00         4\n",
      "          36       0.00      0.00      0.00        26\n",
      "          37       0.00      0.00      0.00        15\n",
      "          38       0.58      0.13      0.21       111\n",
      "          39       0.50      0.03      0.05        77\n",
      "          40       0.00      0.00      0.00         4\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00        28\n",
      "          43       0.75      0.02      0.03       354\n",
      "          44       0.00      0.00      0.00        85\n",
      "          45       0.00      0.00      0.00        57\n",
      "          46       0.00      0.00      0.00         3\n",
      "          47       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         8\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00        12\n",
      "          52       0.00      0.00      0.00         4\n",
      "          53       0.00      0.00      0.00        41\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.78      0.06      0.11       120\n",
      "          56       0.00      0.00      0.00         9\n",
      "          57       0.00      0.00      0.00         4\n",
      "          58       0.00      0.00      0.00        22\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.00      0.00      0.00         8\n",
      "          61       0.00      0.00      0.00         6\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00        19\n",
      "          64       0.00      0.00      0.00        18\n",
      "          65       0.00      0.00      0.00        15\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         3\n",
      "          68       0.00      0.00      0.00        10\n",
      "          69       0.00      0.00      0.00         3\n",
      "          70       0.00      0.00      0.00         8\n",
      "          71       0.00      0.00      0.00        11\n",
      "          72       0.00      0.00      0.00         9\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00        25\n",
      "          75       0.00      0.00      0.00        47\n",
      "          76       0.00      0.00      0.00         6\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         7\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00         5\n",
      "          83       0.00      0.00      0.00        56\n",
      "          84       0.00      0.00      0.00        16\n",
      "          85       0.00      0.00      0.00        32\n",
      "          86       0.67      0.64      0.65      2354\n",
      "          87       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.84      0.63      0.72     15286\n",
      "   macro avg       0.11      0.04      0.05     15286\n",
      "weighted avg       0.73      0.63      0.65     15286\n",
      " samples avg       0.88      0.73      0.76     15286\n",
      "\n",
      "Progress: 40.00% complete\n",
      "\n",
      "Hist Gradient Boosting Validation Micro F1 Score: 0.7257\n",
      "Hist Gradient Boosting Validation Macro F1 Score: 0.2214\n",
      "Hist Gradient Boosting Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.02      0.09      0.03        11\n",
      "           2       0.05      0.20      0.08        10\n",
      "           3       0.02      0.17      0.03         6\n",
      "           4       0.68      0.20      0.31      1150\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.04      0.11      0.06         9\n",
      "           8       0.91      0.53      0.67        19\n",
      "           9       0.83      0.44      0.58       238\n",
      "          10       0.80      0.38      0.51       103\n",
      "          11       0.94      0.93      0.93      4526\n",
      "          12       0.78      0.23      0.36        30\n",
      "          13       0.25      0.17      0.21        23\n",
      "          14       0.92      0.22      0.36        49\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.19      0.75      0.30         4\n",
      "          17       0.64      0.22      0.33        32\n",
      "          18       0.07      0.33      0.11         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.94      0.36      0.52        90\n",
      "          21       0.62      0.23      0.33        22\n",
      "          22       0.68      0.27      0.39        48\n",
      "          23       0.87      0.22      0.35        59\n",
      "          24       0.00      0.00      0.00        41\n",
      "          25       0.89      0.85      0.87      4393\n",
      "          26       0.00      0.00      0.00         9\n",
      "          27       0.78      0.51      0.62        55\n",
      "          28       0.86      0.16      0.26        77\n",
      "          29       0.78      0.32      0.45        22\n",
      "          30       1.00      0.16      0.28       187\n",
      "          31       1.00      0.20      0.33        20\n",
      "          32       0.05      0.10      0.07        10\n",
      "          33       0.00      0.00      0.00         7\n",
      "          34       0.86      0.26      0.39       305\n",
      "          35       0.00      0.00      0.00         4\n",
      "          36       0.83      0.38      0.53        26\n",
      "          37       0.21      0.40      0.27        15\n",
      "          38       0.82      0.48      0.60       111\n",
      "          39       0.53      0.21      0.30        77\n",
      "          40       0.00      0.00      0.00         4\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       1.00      0.54      0.70        28\n",
      "          43       0.96      0.12      0.22       354\n",
      "          44       0.96      0.26      0.41        85\n",
      "          45       0.65      0.19      0.30        57\n",
      "          46       0.00      0.00      0.00         3\n",
      "          47       0.00      0.00      0.00         3\n",
      "          48       0.08      0.25      0.12         8\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00        12\n",
      "          52       0.00      0.00      0.00         4\n",
      "          53       1.00      0.15      0.26        41\n",
      "          54       0.77      0.45      0.57        22\n",
      "          55       0.77      0.28      0.40       120\n",
      "          56       0.15      0.22      0.18         9\n",
      "          57       0.00      0.00      0.00         4\n",
      "          58       0.27      0.14      0.18        22\n",
      "          59       0.04      0.33      0.08         6\n",
      "          60       0.00      0.00      0.00         8\n",
      "          61       0.00      0.00      0.00         6\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.60      0.63      0.62        19\n",
      "          64       0.46      0.33      0.39        18\n",
      "          65       0.38      0.20      0.26        15\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         3\n",
      "          68       0.03      0.10      0.05        10\n",
      "          69       0.03      0.33      0.05         3\n",
      "          70       0.00      0.00      0.00         8\n",
      "          71       0.08      0.18      0.11        11\n",
      "          72       0.07      0.11      0.08         9\n",
      "          73       0.12      0.33      0.18         3\n",
      "          74       0.42      0.20      0.27        25\n",
      "          75       1.00      0.26      0.41        47\n",
      "          76       0.09      0.50      0.16         6\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.14      0.43      0.21         7\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.03      0.20      0.05         5\n",
      "          83       1.00      0.29      0.44        56\n",
      "          84       0.13      0.12      0.13        16\n",
      "          85       0.82      0.28      0.42        32\n",
      "          86       0.68      0.67      0.67      2354\n",
      "          87       0.20      0.14      0.16        22\n",
      "\n",
      "   micro avg       0.77      0.69      0.73     15286\n",
      "   macro avg       0.36      0.21      0.22     15286\n",
      "weighted avg       0.83      0.69      0.72     15286\n",
      " samples avg       0.83      0.77      0.76     15286\n",
      "\n",
      "Progress: 60.00% complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Validation Micro F1 Score: 0.6951\n",
      "K-Nearest Neighbors Validation Macro F1 Score: 0.1300\n",
      "K-Nearest Neighbors Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       1.00      0.20      0.33        10\n",
      "           3       0.20      0.17      0.18         6\n",
      "           4       0.46      0.36      0.41      1150\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.56      0.26      0.36        19\n",
      "           9       0.50      0.32      0.39       238\n",
      "          10       0.38      0.15      0.21       103\n",
      "          11       0.89      0.88      0.88      4526\n",
      "          12       0.14      0.03      0.05        30\n",
      "          13       1.00      0.04      0.08        23\n",
      "          14       0.33      0.06      0.10        49\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       1.00      0.25      0.40         4\n",
      "          17       0.50      0.09      0.16        32\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.46      0.14      0.22        90\n",
      "          21       0.00      0.00      0.00        22\n",
      "          22       0.25      0.04      0.07        48\n",
      "          23       0.32      0.12      0.17        59\n",
      "          24       0.08      0.02      0.04        41\n",
      "          25       0.84      0.83      0.83      4393\n",
      "          26       0.00      0.00      0.00         9\n",
      "          27       0.50      0.40      0.44        55\n",
      "          28       0.16      0.06      0.09        77\n",
      "          29       0.25      0.09      0.13        22\n",
      "          30       0.26      0.10      0.14       187\n",
      "          31       1.00      0.05      0.10        20\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         7\n",
      "          34       0.46      0.21      0.29       305\n",
      "          35       0.00      0.00      0.00         4\n",
      "          36       0.60      0.12      0.19        26\n",
      "          37       0.19      0.27      0.22        15\n",
      "          38       0.37      0.31      0.33       111\n",
      "          39       0.16      0.09      0.12        77\n",
      "          40       0.00      0.00      0.00         4\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.67      0.14      0.24        28\n",
      "          43       0.35      0.21      0.26       354\n",
      "          44       0.24      0.09      0.13        85\n",
      "          45       0.14      0.09      0.11        57\n",
      "          46       0.00      0.00      0.00         3\n",
      "          47       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         8\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.67      0.17      0.27        12\n",
      "          52       0.00      0.00      0.00         4\n",
      "          53       0.08      0.02      0.04        41\n",
      "          54       0.21      0.14      0.17        22\n",
      "          55       0.44      0.18      0.26       120\n",
      "          56       0.00      0.00      0.00         9\n",
      "          57       0.00      0.00      0.00         4\n",
      "          58       0.20      0.05      0.07        22\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.00      0.00      0.00         8\n",
      "          61       0.00      0.00      0.00         6\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.50      0.26      0.34        19\n",
      "          64       0.80      0.22      0.35        18\n",
      "          65       0.00      0.00      0.00        15\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         3\n",
      "          68       0.00      0.00      0.00        10\n",
      "          69       0.00      0.00      0.00         3\n",
      "          70       0.00      0.00      0.00         8\n",
      "          71       0.60      0.27      0.37        11\n",
      "          72       0.00      0.00      0.00         9\n",
      "          73       0.33      0.33      0.33         3\n",
      "          74       0.83      0.20      0.32        25\n",
      "          75       0.43      0.06      0.11        47\n",
      "          76       0.50      0.17      0.25         6\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         7\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00         5\n",
      "          83       0.18      0.04      0.06        56\n",
      "          84       0.00      0.00      0.00        16\n",
      "          85       0.25      0.06      0.10        32\n",
      "          86       0.63      0.60      0.61      2354\n",
      "          87       0.20      0.05      0.07        22\n",
      "\n",
      "   micro avg       0.75      0.65      0.70     15286\n",
      "   macro avg       0.24      0.10      0.13     15286\n",
      "weighted avg       0.70      0.65      0.67     15286\n",
      " samples avg       0.81      0.73      0.73     15286\n",
      "\n",
      "Progress: 80.00% complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier Validation Micro F1 Score: 0.7131\n",
      "Ridge Classifier Validation Macro F1 Score: 0.0310\n",
      "Ridge Classifier Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.59      0.14      0.22      1150\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         9\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.55      0.05      0.09       238\n",
      "          10       0.00      0.00      0.00       103\n",
      "          11       0.93      0.90      0.92      4526\n",
      "          12       0.00      0.00      0.00        30\n",
      "          13       0.00      0.00      0.00        23\n",
      "          14       0.00      0.00      0.00        49\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       0.00      0.00      0.00        32\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00        90\n",
      "          21       0.00      0.00      0.00        22\n",
      "          22       0.00      0.00      0.00        48\n",
      "          23       0.00      0.00      0.00        59\n",
      "          24       0.00      0.00      0.00        41\n",
      "          25       0.86      0.85      0.86      4393\n",
      "          26       0.00      0.00      0.00         9\n",
      "          27       0.00      0.00      0.00        55\n",
      "          28       0.00      0.00      0.00        77\n",
      "          29       0.00      0.00      0.00        22\n",
      "          30       0.00      0.00      0.00       187\n",
      "          31       0.00      0.00      0.00        20\n",
      "          32       0.00      0.00      0.00        10\n",
      "          33       0.00      0.00      0.00         7\n",
      "          34       0.50      0.00      0.01       305\n",
      "          35       0.00      0.00      0.00         4\n",
      "          36       0.00      0.00      0.00        26\n",
      "          37       0.00      0.00      0.00        15\n",
      "          38       0.00      0.00      0.00       111\n",
      "          39       0.00      0.00      0.00        77\n",
      "          40       0.00      0.00      0.00         4\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00        28\n",
      "          43       0.00      0.00      0.00       354\n",
      "          44       0.00      0.00      0.00        85\n",
      "          45       0.00      0.00      0.00        57\n",
      "          46       0.00      0.00      0.00         3\n",
      "          47       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         8\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00        12\n",
      "          52       0.00      0.00      0.00         4\n",
      "          53       0.00      0.00      0.00        41\n",
      "          54       0.00      0.00      0.00        22\n",
      "          55       0.00      0.00      0.00       120\n",
      "          56       0.00      0.00      0.00         9\n",
      "          57       0.00      0.00      0.00         4\n",
      "          58       0.00      0.00      0.00        22\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.00      0.00      0.00         8\n",
      "          61       0.00      0.00      0.00         6\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00        19\n",
      "          64       0.00      0.00      0.00        18\n",
      "          65       0.00      0.00      0.00        15\n",
      "          66       0.00      0.00      0.00         2\n",
      "          67       0.00      0.00      0.00         3\n",
      "          68       0.00      0.00      0.00        10\n",
      "          69       0.00      0.00      0.00         3\n",
      "          70       0.00      0.00      0.00         8\n",
      "          71       0.00      0.00      0.00        11\n",
      "          72       0.00      0.00      0.00         9\n",
      "          73       0.00      0.00      0.00         3\n",
      "          74       0.00      0.00      0.00        25\n",
      "          75       0.00      0.00      0.00        47\n",
      "          76       0.00      0.00      0.00         6\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         7\n",
      "          81       0.00      0.00      0.00         3\n",
      "          82       0.00      0.00      0.00         5\n",
      "          83       0.00      0.00      0.00        56\n",
      "          84       0.00      0.00      0.00        16\n",
      "          85       0.00      0.00      0.00        32\n",
      "          86       0.68      0.60      0.64      2354\n",
      "          87       0.00      0.00      0.00        22\n",
      "\n",
      "   micro avg       0.85      0.62      0.71     15286\n",
      "   macro avg       0.05      0.03      0.03     15286\n",
      "weighted avg       0.69      0.62      0.63     15286\n",
      " samples avg       0.88      0.72      0.75     15286\n",
      "\n",
      "Progress: 100.00% complete\n",
      "\n",
      "\n",
      "Test Classification Report (Hist Gradient Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.20      0.10         5\n",
      "           1       0.03      0.11      0.05         9\n",
      "           2       0.12      0.50      0.19         4\n",
      "           3       0.05      0.25      0.08         8\n",
      "           4       0.70      0.18      0.29      1256\n",
      "           5       0.14      0.40      0.21         5\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       0.33      0.29      0.31        14\n",
      "           8       0.86      0.26      0.40        23\n",
      "           9       0.85      0.48      0.61       233\n",
      "          10       0.82      0.32      0.46       100\n",
      "          11       0.94      0.93      0.94      4535\n",
      "          12       0.20      0.05      0.08        40\n",
      "          13       0.00      0.00      0.00        15\n",
      "          14       0.00      0.00      0.00        39\n",
      "          15       0.10      0.50      0.16         4\n",
      "          16       0.08      0.60      0.14         5\n",
      "          17       0.57      0.29      0.38        14\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.88      0.31      0.45        95\n",
      "          21       0.00      0.00      0.00        19\n",
      "          22       0.94      0.34      0.50        50\n",
      "          23       0.86      0.27      0.41        66\n",
      "          24       0.70      0.16      0.25        45\n",
      "          25       0.90      0.85      0.87      4358\n",
      "          26       0.13      0.18      0.15        11\n",
      "          27       0.62      0.40      0.49        70\n",
      "          28       1.00      0.38      0.56        65\n",
      "          29       0.86      0.27      0.41        22\n",
      "          30       0.94      0.19      0.31       181\n",
      "          31       0.27      0.12      0.17        24\n",
      "          32       0.13      0.29      0.18         7\n",
      "          33       0.00      0.00      0.00         8\n",
      "          34       0.78      0.25      0.38       303\n",
      "          35       0.00      0.00      0.00         5\n",
      "          36       0.90      0.39      0.55        23\n",
      "          37       0.06      0.23      0.09        13\n",
      "          38       0.79      0.51      0.62       104\n",
      "          39       0.65      0.23      0.34        75\n",
      "          40       0.05      0.17      0.07         6\n",
      "          41       0.06      0.50      0.11         2\n",
      "          42       1.00      0.37      0.54        27\n",
      "          43       0.86      0.10      0.18       376\n",
      "          44       0.97      0.34      0.50        89\n",
      "          45       0.71      0.20      0.31        61\n",
      "          46       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         2\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         7\n",
      "          52       0.00      0.00      0.00         3\n",
      "          53       0.70      0.16      0.25        45\n",
      "          54       0.82      0.38      0.51        24\n",
      "          55       0.63      0.21      0.31       106\n",
      "          56       0.04      0.11      0.06         9\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.17      0.06      0.09        35\n",
      "          59       0.00      0.00      0.00         2\n",
      "          60       0.03      0.50      0.05         2\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.10      0.17      0.12         6\n",
      "          63       0.47      0.47      0.47        19\n",
      "          64       0.83      0.33      0.48        15\n",
      "          65       0.00      0.00      0.00         6\n",
      "          66       0.00      0.00      0.00         5\n",
      "          67       0.03      0.17      0.04         6\n",
      "          68       0.03      0.20      0.05         5\n",
      "          69       0.00      0.00      0.00         3\n",
      "          70       0.03      0.17      0.05         6\n",
      "          71       0.14      0.24      0.18        17\n",
      "          72       0.03      0.33      0.06         3\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       1.00      0.15      0.26        27\n",
      "          75       0.92      0.31      0.47        35\n",
      "          76       0.00      0.00      0.00         5\n",
      "          77       0.00      0.00      0.00        13\n",
      "          78       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         9\n",
      "          80       0.03      0.10      0.04        10\n",
      "          81       0.02      0.17      0.03         6\n",
      "          82       0.00      0.00      0.00         5\n",
      "          83       0.85      0.31      0.45        36\n",
      "          84       0.20      0.06      0.09        18\n",
      "          85       0.58      0.23      0.33        31\n",
      "          86       0.67      0.67      0.67      2323\n",
      "          87       0.64      0.26      0.37        35\n",
      "\n",
      "   micro avg       0.77      0.68      0.72     15320\n",
      "   macro avg       0.34      0.21      0.21     15320\n",
      "weighted avg       0.82      0.68      0.71     15320\n",
      " samples avg       0.83      0.77      0.76     15320\n",
      "\n",
      "\n",
      "Training and Inference Times:\n",
      "Naive Bayes - Training time: 6.2595 seconds, Inference time: 0.5039 seconds\n",
      "Logistic Regression - Training time: 38.7031 seconds, Inference time: 0.7822 seconds\n",
      "Hist Gradient Boosting - Training time: 285.8145 seconds, Inference time: 6.1331 seconds\n",
      "K-Nearest Neighbors - Training time: 49.7255 seconds, Inference time: 572.2247 seconds\n",
      "Ridge Classifier - Training time: 11.0856 seconds, Inference time: 0.4509 seconds\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Load data\n",
    "with open('arxiv_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'title': data['titles'],\n",
    "    'abstract': data['summaries'],\n",
    "    'labels': data['terms']\n",
    "})\n",
    "\n",
    "# Preprocess text\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['abstract'] = df['abstract'].apply(preprocess_text)\n",
    "\n",
    "# Convert labels to binary matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['labels'])\n",
    "\n",
    "# Split dataset\n",
    "train_texts, test_texts, y_train, y_test = train_test_split(df['abstract'], y, test_size=0.15, random_state=42)\n",
    "train_texts, val_texts, y_train, y_val = train_test_split(train_texts, y_train, test_size=0.1765, random_state=42)\n",
    "\n",
    "# Vectorize text\n",
    "tfidf = TfidfVectorizer(max_features=500)\n",
    "X_train = tfidf.fit_transform(train_texts).toarray()\n",
    "X_val = tfidf.transform(val_texts).toarray()\n",
    "X_test = tfidf.transform(test_texts).toarray()\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Hist Gradient Boosting': HistGradientBoostingClassifier(max_iter=100),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Ridge Classifier': RidgeClassifier()\n",
    "}\n",
    "\n",
    "# Track metrics\n",
    "train_times = {}\n",
    "inference_times = {}\n",
    "val_micro_f1_scores = {}\n",
    "val_macro_f1_scores = {}\n",
    "reports = {}\n",
    "\n",
    "# Train and evaluate models\n",
    "total_models = len(models)\n",
    "for idx, (name, model) in enumerate(models.items(), start=1):\n",
    "    multi_target_model = MultiOutputClassifier(model, n_jobs=-1)\n",
    "    \n",
    "    # Training time\n",
    "    start_time = time.time()\n",
    "    multi_target_model.fit(X_train, y_train)\n",
    "    train_times[name] = time.time() - start_time\n",
    "    \n",
    "    # Inference time\n",
    "    start_time = time.time()\n",
    "    y_val_pred = multi_target_model.predict(X_val)\n",
    "    inference_times[name] = time.time() - start_time\n",
    "    \n",
    "    # Calculate micro and macro F1 scores\n",
    "    micro_f1 = f1_score(y_val, y_val_pred, average='micro')\n",
    "    macro_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "    val_micro_f1_scores[name] = micro_f1\n",
    "    val_macro_f1_scores[name] = macro_f1\n",
    "    \n",
    "    print(f\"{name} Validation Micro F1 Score: {micro_f1:.4f}\")\n",
    "    print(f\"{name} Validation Macro F1 Score: {macro_f1:.4f}\")\n",
    "    \n",
    "    # Generate classification report\n",
    "    reports[name] = classification_report(y_val, y_val_pred, zero_division=0)\n",
    "    print(f\"{name} Validation Classification Report:\\n{reports[name]}\")\n",
    "    \n",
    "    # Show progress\n",
    "    progress = (idx / total_models) * 100\n",
    "    print(f\"Progress: {progress:.2f}% complete\\n\")\n",
    "\n",
    "# Select best model based on micro F1 score and generate test report\n",
    "best_model_name = max(val_micro_f1_scores, key=val_micro_f1_scores.get)\n",
    "best_model = MultiOutputClassifier(models[best_model_name], n_jobs=-1)\n",
    "best_model.fit(X_train, y_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_report = classification_report(y_test, y_test_pred, zero_division=0)\n",
    "print(f\"\\nTest Classification Report ({best_model_name}):\\n{test_report}\")\n",
    "\n",
    "# Display training and inference times\n",
    "print(\"\\nTraining and Inference Times:\")\n",
    "for name in models.keys():\n",
    "    print(f\"{name} - Training time: {train_times[name]:.4f} seconds, Inference time: {inference_times[name]:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb4161-54bc-4ed6-8ddf-65da7befb78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
