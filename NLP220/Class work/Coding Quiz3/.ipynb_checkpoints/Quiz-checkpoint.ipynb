{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88bf633d-221e-4bf0-9f02-b746adab828c",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0890b3c0-c54a-424b-ae28-b1a8bca9f1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank/Frequency profile saved to 'rank_freq_profile.csv'.\n",
      "Percentage of corpus size made up by top-10 words: 20.68%\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import twitter_samples\n",
    "import re\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Download required resources if not already present\n",
    "nltk.download('twitter_samples')\n",
    "\n",
    "# Load Twitter Corpus\n",
    "tweets = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "\n",
    "# Data Cleaning: Remove Tweet handles, URLs, hashtags, and short sentences\n",
    "cleaned_tweets = []\n",
    "url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "handle_pattern = re.compile(r'@\\w+')\n",
    "hashtag_pattern = re.compile(r'#\\w+')\n",
    "\n",
    "for tweet in tweets:\n",
    "    # Remove URLs and handles\n",
    "    tweet = url_pattern.sub('', tweet)\n",
    "    tweet = handle_pattern.sub('', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = hashtag_pattern.sub('', tweet)\n",
    "    # Tokenize and check token count\n",
    "    tokens = tweet.split()\n",
    "    if len(tokens) >= 4:\n",
    "        cleaned_tweets.append(' '.join(tokens))\n",
    "\n",
    "# Create a frequency distribution\n",
    "all_words = ' '.join(cleaned_tweets).split()\n",
    "freq_dist = Counter(all_words)\n",
    "\n",
    "# Rank/ frequency profile\n",
    "ranked_words = sorted(freq_dist.items(), key=lambda x: x[1], reverse=True)\n",
    "rank_freq_profile = [\n",
    "    {\"word\": word, \"rank\": rank + 1, \"freq\": freq}\n",
    "    for rank, (word, freq) in enumerate(ranked_words)\n",
    "]\n",
    "\n",
    "# Save the top-100 rank/frequency profile to a CSV file\n",
    "output_file = 'rank_freq_profile.csv'\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Word', 'Rank', 'Frequency'])\n",
    "    for entry in rank_freq_profile[:100]:\n",
    "        writer.writerow([entry[\"word\"], entry[\"rank\"], entry[\"freq\"]])\n",
    "\n",
    "# Compute the percentage of corpus size made up by the top-10 words\n",
    "total_words = sum(freq_dist.values())\n",
    "top_10_freq = sum([freq for _, freq in ranked_words[:10]])\n",
    "percentage_top_10 = (top_10_freq / total_words) * 100\n",
    "\n",
    "# Output results\n",
    "print(f\"Rank/Frequency profile saved to '{output_file}'.\")\n",
    "print(f\"Percentage of corpus size made up by top-10 words: {percentage_top_10:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4663e0-78fc-495b-9cab-5737bf26ab86",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8f61b-7f2c-42ca-b67e-9c7bae10fbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57d79c33-951d-4b1d-a7cf-2d2c9518bf73",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ca4d9-d2c3-422a-9a3e-56206801f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom import minidom\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# Load the XML file using DOM parsing\n",
    "xml_file_path = './movies-new.xml'\n",
    "dom_tree = minidom.parse(xml_file_path)\n",
    "\n",
    "# Find all movies\n",
    "movies = dom_tree.getElementsByTagName(\"movie\")\n",
    "\n",
    "# Extract required details and prepare data\n",
    "movie_data = []\n",
    "for movie in movies:\n",
    "    title = movie.getAttribute(\"title\")\n",
    "    year = movie.getElementsByTagName(\"year\")[0].firstChild.data\n",
    "    rating = movie.getElementsByTagName(\"rating\")[0].firstChild.data\n",
    "    description = movie.getElementsByTagName(\"description\")[0].firstChild.data.strip()\n",
    "    movie_data.append({\"title\": title, \"year\": int(year), \"rating\": rating, \"description\": description})\n",
    "\n",
    "# Save the data to a CSV file\n",
    "csv_file_path = './movies-new.csv'\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=[\"title\", \"year\", \"rating\", \"description\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(movie_data)\n",
    "\n",
    "# Save the data to a JSON file\n",
    "json_file_path = './movies-new.json'\n",
    "with open(json_file_path, mode='w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(movie_data, jsonfile, indent=4)\n",
    "\n",
    "print(f\"Data saved to {csv_file_path} and {json_file_path}\")\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load the XML file using Element-Tree\n",
    "tree = ET.parse(xml_file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Find all Thriller movies and print their title and year\n",
    "thriller_movies = []\n",
    "for genre in root.findall(\".//genre[@category='Thriller']\"):\n",
    "    for movie in genre.findall(\".//movie\"):\n",
    "        title = movie.attrib.get(\"title\")\n",
    "        year = movie.find(\"year\").text\n",
    "        thriller_movies.append({\"title\": title, \"year\": year})\n",
    "\n",
    "print(\"Thriller Movies:\")\n",
    "for thriller_movie in thriller_movies:\n",
    "    print(f\"Title: {thriller_movie['title']}, Year: {thriller_movie['year']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
