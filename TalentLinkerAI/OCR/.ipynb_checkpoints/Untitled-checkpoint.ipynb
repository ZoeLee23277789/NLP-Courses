{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb7fb106-c1d7-4445-98c5-8619dda9a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 頁的文字（直接擷取）：\n",
      "Jou-Yi Lee\n",
      "65RioRoblesE,SanJose,CA95134•zoelee19991226@gmail.com•+1408-618-9437•+886978-716-05\n",
      "ABOUTME\n",
      "Aspiringcomputerscientistwithastrongbackgroundinengineeringandresearch,aimingtoleverageskillsinmachine\n",
      "learning,robotics,andsoftwaredevelopmentforinnovativeprojectsinnaturallanguageprocessing.\n",
      "SKILLS\n",
      "TechnicalSkills\n",
      "✓ ProgrammingLanguages: C++,Python,MATLAB\n",
      "✓ SoftwareandTools: PyTorch,Selenium,Scrapy,OpenCV,SolidWorks,AutoCAD,Ansys\n",
      "✓ MachineLearningandAI:PyTorch,TensorFlow,Scikit-learn,NLTK,SpaCy\n",
      "✓ EmbeddedSystems: RaspberryPi,Arduino\n",
      "✓ MechanicalDesign: 3DPrinting,PlasticandMetalPartsDesign\n",
      "SoftSkills\n",
      "✓ Self-drivenlearning,Innovation,Problem-solving,Communication\n",
      "RESEARCHPROJECTS\n",
      "FeatureEngineeringandModelEvaluationforE-commerce Sep2024-Nov2024\n",
      "Advisor: JalalMahmud,R&D\n",
      "✓ Optimizedclassifiersforsentimentanalysisandproductcategorization.\n",
      "RelationExtractionfromNaturalLanguage Sep2024-Nov2024\n",
      "Advisor: AmitaMisra,Amazon\n",
      "✓ Builtdeeplearningmodelsforrelationextractioninconversationallanguage.\n",
      "SlotTaggingforNaturalLanguage Sep2024-Nov2024\n",
      "Advisor: AmitaMisra,Amazon\n",
      "✓ DevelopedaPyTorch-basedslottaggingmodelforvirtualassistants.\n",
      "MobileRobotPathPlanningusingQ-Learning Feb2023-Sep2024\n",
      "Advisor: SYEDHUMAYOONSHAH,YuanZeUniversity\n",
      "✓ ImprovedstaticnavigationusingQ-Learningandobjectdetection(OpenCV,YOLOv9).\n",
      "MarineDebrisImageNetVisualRecognition Feb2023-Oct2023\n",
      "Advisor: Ching-LuehChang,YuanZeUniversity\n",
      "✓ Designedvisualrecognitionmodelsformarinedebrisidentification.\n",
      "DeterministicSublinear-TimeApproximationsforMetric1-MedianSelection Feb2022-July2023\n",
      "Advisor: Ching-LuehChang,YuanZeUniversity\n",
      "✓ Developedmetricapproximationsforscalabledataanalysis.\n",
      "EDUCATION\n",
      "MasterofScienceinNaturalLanguageProcessing Sep2024-Present\n",
      "UniversityofCalifornia,SantaCruz\n",
      "✓ CurrentlypursuinggraduatestudiesinNLP\n",
      "BachelorofScienceinEngineering Jul2019-Jun2024\n",
      "YuanZeUniversity,Taoyuan,Taiwan\n",
      "✓ Majors: MechanicalEngineering,ChemicalEngineeringandMaterialsScience,ComputerScience\n",
      "ExchangePrograminComputerScience Jun2023-Sep2023\n",
      "UniversityofCalifornia,Berkeley,USA\n",
      "✓ Participatedinasemester-longexchangeprogram\n",
      "第 2 頁的文字（直接擷取）：\n",
      "EXPERIENCE\n",
      "OperationsAssistant Feb2024-Aug2024\n",
      "HuanzhongCo.,Ltd.,TaoyuanCity,Taiwan\n",
      "✓ Streamlinedsupplychainandmaintenanceprocessesatafuelstation,ensuringregulatorycompliance\n",
      "✓ Assistedinretailoperations,includingstaffmanagementandinventorycontrol\n",
      "ACTIVITIESANDAWARDS\n",
      "✓ MarineDebrisImageNetVisualRecognitionChallenge,Judges’ShortlistAward,Oct2023\n",
      "✓ SecondRunner-Up,MakerCompetition,2019\n",
      "✓ Member,MakerClub,YuanZeUniversity\n",
      "✓ Member,BookClub,YuanZeUniversity\n",
      "NOTABLEPROJECTS\n",
      "RoboticsandMechanicalDesign\n",
      "✓ Bio-mimeticSpiderRobot,PitchingRobot,ColorSortingRobot\n",
      "DeepLearningandReinforcementLearning\n",
      "✓ ImplementedreinforcementlearningalgorithmsusingOpenAIGym(Taxi-v3)andActor-Critic\n",
      "✓ Developedamarinedebrissortingsystem,awardedinacompetition\n",
      "SoftwareDevelopmentandSimulation\n",
      "✓ FerrisWheelDesign,CandyCrushSimulation\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pdf2image\n",
    "import pytesseract\n",
    "\n",
    "pdf_path = \"Resume_UCSC.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for i, page in enumerate(pdf.pages):\n",
    "        text = page.extract_text()\n",
    "        if text:  # 如果能直接提取文字\n",
    "            print(f\"第 {i+1} 頁的文字（直接擷取）：\\n{text}\")\n",
    "        else:  # 如果不能提取文字，則使用 OCR\n",
    "            image = pdf2image.convert_from_path(pdf_path, first_page=i+1, last_page=i+1)[0]\n",
    "            text = pytesseract.image_to_string(image, lang=\"eng\")\n",
    "            print(f\"第 {i+1} 頁的文字（OCR 擷取）：\\n{text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db66d316-8c6e-40cd-98d8-2f8c350496c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "偵測語言：zh-cn\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return lang\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "sample_text = \"你好 ?\"\n",
    "detected_lang = detect_language(sample_text)\n",
    "print(f\"偵測語言：{detected_lang}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "642aa07c-44e0-46ba-9fc8-05ac30c472f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 頁 - 語言：en（內嵌文字）\n",
      "第 2 頁 - 語言：en（內嵌文字）\n",
      "\n",
      "📝 最終 OCR 輸出：\n",
      "Jou-Yi Lee  65Rio Robles E ,San Jose ,CA 95134 zoelee 19991226@gmail .com + 1408- 618- 9437 + 886978- 716- 05 ABOUTME Aspiringcomputerscientistwithastrongbackgroundinengineeringandresearch ,aimingtoleverageskillsinmachine learning ,robotics ,andsoftwaredevelopmentforinnovativeprojectsinnaturallanguageprocessing . SKILLS Technical Skills ✓ Programming Languages: C++,Python ,MATLAB ✓ Softwareand Tools: Py Torch ,Selenium ,Scrapy ,Open CV ,Solid Works ,Auto CAD ,Ansys ✓ Machine Learningand AI:Py Torch ,Tensor Flow ,Scikit-learn ,NLTK ,Spa Cy ✓ Embedded Systems: Raspberry Pi ,Arduino ✓ Mechanical Design:  3DPrinting ,Plasticand Metal Parts Design Soft Skills ✓ Self-drivenlearning ,Innovation ,Problem-solving ,Communication RESEARCHPROJECTS Feature Engineeringand Model Evaluationfor E-commerce Sep 2024-Nov 2024 Advisor: Jalal Mahmud ,R&D ✓ Optimizedclassifiersforsentimentanalysisandproductcategorization . Relation Extractionfrom Natural Language Sep 2024-Nov 2024 Advisor: Amita Misra ,Amazon ✓ Builtdeeplearningmodelsforrelationextractioninconversationallanguage . Slot Taggingfor Natural Language Sep 2024-Nov 2024 Advisor: Amita Misra ,Amazon ✓ Developeda Py Torch-basedslottaggingmodelforvirtualassistants . Mobile Robot Path Planningusing Q-Learning Feb 2023-Sep 2024 Advisor: SYEDHUMAYOONSHAH ,Yuan Ze University ✓ Improvedstaticnavigationusing Q-Learningandobjectdetection(Open CV ,YOLOv 9). Marine Debris Image Net Visual Recognition Feb 2023-Oct 2023 Advisor: Ching-Lueh Chang ,Yuan Ze University ✓ Designedvisualrecognitionmodelsformarinedebrisidentification . Deterministic Sublinear-Time Approximationsfor Metric 1-Median Selection Feb 2022-July 2023 Advisor: Ching-Lueh Chang ,Yuan Ze University ✓ Developedmetricapproximationsforscalabledataanalysis . EDUCATION Masterof Sciencein Natural Language Processing Sep 2024-Present Universityof California ,Santa Cruz ✓ Currentlypursuinggraduatestudiesin NLP Bachelorof Sciencein Engineering Jul 2019-Jun 2024 Yuan Ze University ,Taoyuan ,Taiwan ✓ Majors: Mechanical Engineering ,Chemical Engineeringand Materials Science ,Computer Science Exchange Programin Computer Science Jun 2023-Sep 2023 Universityof California ,Berkeley ,USA ✓ Participatedinasemester-longexchangeprogram\n",
      "EXPERIENCE Operations Assistant Feb 2024-Aug 2024 Huanzhong Co .,Ltd .,Taoyuan City ,Taiwan ✓ Streamlinedsupplychainandmaintenanceprocessesatafuelstation ,ensuringregulatorycompliance ✓ Assistedinretailoperations ,includingstaffmanagementandinventorycontrol ACTIVITIESANDAWARDS ✓ Marine Debris Image Net Visual Recognition Challenge ,Judges’Shortlist Award ,Oct 2023 ✓ Second Runner-Up ,Maker Competition , 2019 ✓ Member ,Maker Club ,Yuan Ze University ✓ Member ,Book Club ,Yuan Ze University NOTABLEPROJECTS Roboticsand Mechanical Design ✓ Bio-mimetic Spider Robot ,Pitching Robot ,Color Sorting Robot Deep Learningand Reinforcement Learning ✓ Implementedreinforcementlearningalgorithmsusing Open AIGym(Taxi-v 3)and Actor-Critic ✓ Developedamarinedebrissortingsystem ,awardedinacompetition Software Developmentand Simulation ✓ Ferris Wheel Design ,Candy Crush Simulation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pdf2image\n",
    "import pytesseract\n",
    "import re\n",
    "from langdetect import detect\n",
    "from easyocr import Reader\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "\n",
    "# TrOCR 模型（手寫辨識）\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\", ignore_mismatched_sizes=True)\n",
    "\n",
    "# EasyOCR（單獨處理不同語言）\n",
    "reader_chinese_tra = Reader(['ch_tra', 'en'])\n",
    "reader_chinese_sim = Reader(['ch_sim', 'en'])\n",
    "reader_japanese = Reader(['ja', 'en'])\n",
    "reader_korean = Reader(['ko', 'en'])\n",
    "reader_russian = Reader(['ru', 'en'])\n",
    "reader_arabic = Reader(['ar', 'en'])\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"偵測語言\"\"\"\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "def easyocr_multilang(image):\n",
    "    \"\"\"使用 EasyOCR，強制加入單詞間距\"\"\"\n",
    "    final_text = []\n",
    "    \n",
    "    def process_reader(reader, lang_name):\n",
    "        print(f\"正在使用 {lang_name} OCR...\")\n",
    "        results = reader.readtext(image)\n",
    "        text = \" \".join([res[1] for res in results])  # 強制加入空格\n",
    "        final_text.append(text)\n",
    "\n",
    "    process_reader(reader_chinese_tra, \"繁體中文\")\n",
    "    process_reader(reader_chinese_sim, \"簡體中文\")\n",
    "    process_reader(reader_japanese, \"日文\")\n",
    "    process_reader(reader_korean, \"韓文\")\n",
    "    process_reader(reader_russian, \"俄文\")\n",
    "    process_reader(reader_arabic, \"阿拉伯文\")\n",
    "\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "def fix_spacing(text):\n",
    "    \"\"\"自動修正沒有空格的單詞\"\"\"\n",
    "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)  # 小寫 + 大寫之間補上空格\n",
    "    text = re.sub(r'(\\w)([,.!?])', r'\\1 \\2', text)  # 單詞與標點符號之間加入空格\n",
    "    text = re.sub(r'(\\D)(\\d)', r'\\1 \\2', text)  # 非數字+數字之間加入空格\n",
    "    return text\n",
    "\n",
    "def ocr_pipeline(pdf_path):\n",
    "    \"\"\"OCR 處理流程\"\"\"\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            if text:  # ✅ 內嵌文字可直接提取\n",
    "                text = text.replace(\"\\n\", \" \").replace(\"•\", \" \")  # 修正 PDF 內嵌格式問題\n",
    "                detected_lang = detect_language(text)\n",
    "                print(f\"第 {i+1} 頁 - 語言：{detected_lang}（內嵌文字）\")\n",
    "                extracted_text += text + \"\\n\"\n",
    "            else:\n",
    "                # 🚀 PDF 轉換為圖片\n",
    "                image = pdf2image.convert_from_path(pdf_path, first_page=i+1, last_page=i+1)[0]\n",
    "\n",
    "                # ✅ 使用 Tesseract OCR，確保單詞之間有間格\n",
    "                text_ocr = pytesseract.image_to_string(\n",
    "                    image, lang=\"eng+chi_tra+jpn+kor+ara+rus\",\n",
    "                    config=\"--oem 3 --psm 6 -c preserve_interword_spaces=1\"\n",
    "                )\n",
    "                detected_lang = detect_language(text_ocr)\n",
    "\n",
    "                # ✅ 如果 Tesseract OCR 結果太短，改用 EasyOCR\n",
    "                if len(text_ocr.strip()) < 10:\n",
    "                    text_easyocr = easyocr_multilang(image)\n",
    "                    detected_lang = detect_language(text_easyocr)\n",
    "                    text_ocr = text_easyocr\n",
    "\n",
    "                # ✅ 如果是手寫字或難識別內容，改用 TrOCR\n",
    "                if detected_lang in [\"en\", \"zh-cn\", \"zh-tw\", \"ja\"]:\n",
    "                    image = image.convert(\"RGB\")\n",
    "                    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "                    generated_ids = model.generate(pixel_values)\n",
    "                    text_trocr = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "                    text_ocr = text_trocr\n",
    "\n",
    "                print(f\"第 {i+1} 頁 - 語言：{detected_lang}\")\n",
    "                extracted_text += text_ocr + \"\\n\"\n",
    "\n",
    "    # 修正間隔問題\n",
    "    extracted_text = fix_spacing(extracted_text)\n",
    "    return extracted_text\n",
    "\n",
    "# 測試 OCR\n",
    "pdf_path = \"Resume_UCSC.pdf\"\n",
    "text_output = ocr_pipeline(pdf_path)\n",
    "\n",
    "print(\"\\n📝 最終 OCR 輸出：\")\n",
    "print(text_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6b2712d-0939-47c3-913e-22666d55abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 頁的文字（直接擷取 + 修正空格）：\n",
      "jouyilee65rioroblese san jose ca95134 zoelee19991226@gmail.com  +1408-618-9437  +886978-716 05 about me aspiring computer scientist with a strong background in engineering and research aiming to leverage skills in machine learning robotics and software development for innovative projects in natural language processing skills technical skills programming languages cpython matlab software and tools py torch selenium scrap y opencv solidworks autocad ansys machine learning and a ipy torch tensor flow sci kit learn nl tk spacy embedded systems raspberry pi arduino mechanical design 3d printing plastic and metal parts design soft skills self driven learning innovation problem solving communication research projects feature engineering and model evaluation for ecommerce sep2024nov2024 advisor jalal mahmud rd optimized classifiers for sentiment analysis and product categorization relation extraction from natural language sep2024nov2024 advisor amita misra amazon built deep learning models for relation extraction in conversational languages lot tagging for natural language sep2024nov2024 advisor amita misra amazon developed apy torch based slot tagging model for virtual assistants mobile robot path planning using q learning feb2023sep2024 advisors yedhumayoonshahyuanze university improved static navigation using q learning and object detection open cvyolov9 marine debris image net visual recognition feb2023oct2023 advisor chingluehchangyuanze university designed visual recognition models for marine debris identification deterministic sublinear time approximations for metric 1 median selection feb2022july2023 advisor chingluehchangyuanze university developed metric approximations for scalable data analysis education master of science in natural language processing sep2024 present university of california santa cruz currently pursuing graduate studies in nlp bachelor of science in engineering jul2019jun2024yuanze university taoyuan taiwan majors mechanical engineering chemical engineering and materials science computer science exchange program in computer science jun2023sep2023 university of california berkeley usa participated in a semester long exchange program\n",
      "第 2 頁的文字（直接擷取 + 修正空格）：\n",
      "experience operations assistant feb 2024aug2024huanzhongco ltd taoyuan city taiwan streamlined supply chain and maintenance processes at a fuel station ensuring regulatory compliance assisted in retail operations including staff management and inventory control activities and awards marine debris image net visual recognition challenge judges shortlist award oct2023 second runner up maker competition 2019membermakerclubyuanz e university member book club yuan ze university notable projects robotics and mechanical design biomimetic spider robot pitching robot color sorting robot deep learning and reinforcement learning implemented reinforcement learning algorithms using open aigymtaxiv3 and actor critic developed a marine debris sorting system awarded in a competition software development and simulation ferris wheel design candy crush simulation\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pdf2image\n",
    "import pytesseract\n",
    "import re\n",
    "from wordsegment import load, segment\n",
    "\n",
    "# 加載 wordsegment 的統計模型\n",
    "load()\n",
    "\n",
    "def fix_spacing_with_regex(text):\n",
    "    \"\"\"使用 Regular Expression 修正標點、數字與文字格式（不影響 Gmail & Phone）\"\"\"\n",
    "    \n",
    "    # **先找到 Email 和電話號碼**\n",
    "    email_pattern = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
    "    phone_pattern = r'(\\+?\\d{1,4}[-.\\s]?\\d{2,4}[-.\\s]?\\d{3,4}[-.\\s]?\\d{3,4})'\n",
    "    \n",
    "    all_matches = []\n",
    "    for match in re.finditer(email_pattern, text):\n",
    "        all_matches.append((match.start(), match.end(), match.group()))\n",
    "    for match in re.finditer(phone_pattern, text):\n",
    "        all_matches.append((match.start(), match.end(), match.group()))\n",
    "    \n",
    "    all_matches.sort(key=lambda x: x[0])\n",
    "\n",
    "    fixed_parts = []\n",
    "    last_end = 0\n",
    "\n",
    "    for start, end, value in all_matches:\n",
    "        normal_text = text[last_end:start]\n",
    "        if normal_text.strip():  \n",
    "            # **修正格式**\n",
    "            normal_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', normal_text)  \n",
    "            normal_text = re.sub(r'(\\w)([,.!?])', r'\\1 \\2', normal_text)  \n",
    "\n",
    "            # **核心修正點**\n",
    "            normal_text = re.sub(r'([a-zA-Z]+)(\\d+)([a-zA-Z]+)(\\d+)', r'\\1 \\2 \\3 \\4', normal_text)  # **處理「文字+數字+文字+數字」**\n",
    "            normal_text = re.sub(r'([a-zA-Z]+)(\\d+)', r'\\1 \\2', normal_text)  # **處理「文字+數字」**\n",
    "            normal_text = re.sub(r'(\\d+)([a-zA-Z]+)', r'\\1 \\2', normal_text)  # **處理「數字+文字」**\n",
    "            normal_text = re.sub(r'(\\D)(\\d)', r'\\1 \\2', normal_text)  # **處理「非數字+數字」**\n",
    "            normal_text = re.sub(r'(\\d)(\\D)', r'\\1 \\2', normal_text)  # **處理「數字+非數字」**\n",
    "\n",
    "            fixed_parts.append(normal_text)\n",
    "\n",
    "        # **直接添加原始 Email 和 Phone**\n",
    "        fixed_parts.append(value)\n",
    "        last_end = end\n",
    "\n",
    "    if last_end < len(text):\n",
    "        remaining_text = text[last_end:]\n",
    "        remaining_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', remaining_text)  \n",
    "        remaining_text = re.sub(r'(\\w)([,.!?])', r'\\1 \\2', remaining_text)  \n",
    "\n",
    "        # **核心修正點**\n",
    "        remaining_text = re.sub(r'([a-zA-Z]+)(\\d+)([a-zA-Z]+)(\\d+)', r'\\1 \\2 \\3 \\4', remaining_text)  # **處理「文字+數字+文字+數字」**\n",
    "        remaining_text = re.sub(r'([a-zA-Z]+)(\\d+)', r'\\1 \\2', remaining_text)  # **處理「文字+數字」**\n",
    "        remaining_text = re.sub(r'(\\d+)([a-zA-Z]+)', r'\\1 \\2', remaining_text)  # **處理「數字+文字」**\n",
    "        remaining_text = re.sub(r'(\\D)(\\d)', r'\\1 \\2', remaining_text)  # **處理「非數字+數字」**\n",
    "        remaining_text = re.sub(r'(\\d)(\\D)', r'\\1 \\2', remaining_text)  # **處理「數字+非數字」**\n",
    "\n",
    "        fixed_parts.append(remaining_text)\n",
    "\n",
    "    return \" \".join(fixed_parts)\n",
    "\n",
    "\n",
    "def preserve_format(text):\n",
    "    \"\"\"保留 Gmail 和電話號碼，對其他部分使用 wordsegment 修正單詞間距\"\"\"\n",
    "    \n",
    "    # **更嚴謹的 Gmail 和電話號碼匹配**\n",
    "    email_pattern = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
    "    phone_pattern = r'(\\+?\\d{1,4}[-.\\s]?\\d{2,4}[-.\\s]?\\d{3,4}[-.\\s]?\\d{3,4})'\n",
    "\n",
    "    # **先找到 Email 和電話號碼**\n",
    "    all_matches = []\n",
    "    \n",
    "    for match in re.finditer(email_pattern, text):\n",
    "        all_matches.append((match.start(), match.end(), match.group()))\n",
    "\n",
    "    for match in re.finditer(phone_pattern, text):\n",
    "        all_matches.append((match.start(), match.end(), match.group()))\n",
    "\n",
    "    # **依照出現順序排序**\n",
    "    all_matches.sort(key=lambda x: x[0])\n",
    "\n",
    "    # **分割文本，確保 Email 和 Phone 不進入 `wordsegment`**\n",
    "    segmented_parts = []\n",
    "    last_end = 0\n",
    "\n",
    "    for start, end, value in all_matches:\n",
    "        # 取出上次匹配後的普通文字部分，並用 wordsegment 處理\n",
    "        normal_text = text[last_end:start]\n",
    "        if normal_text.strip():  # 避免多餘的空白段落\n",
    "            segmented_parts.append(\" \".join(segment(normal_text)))\n",
    "\n",
    "        # 直接添加原始的 Email 或 Phone，不做任何處理\n",
    "        segmented_parts.append(value)\n",
    "\n",
    "        last_end = end\n",
    "\n",
    "    # **處理最後一段文字（如果有的話）**\n",
    "    if last_end < len(text):\n",
    "        remaining_text = text[last_end:]\n",
    "        segmented_parts.append(\" \".join(segment(remaining_text)))\n",
    "\n",
    "    # **組合回原始文本**\n",
    "    return \" \".join(segmented_parts)\n",
    "\n",
    "pdf_path = \"Resume_UCSC.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for i, page in enumerate(pdf.pages):\n",
    "        text = page.extract_text()\n",
    "        if text:  \n",
    "            # **先修正標點與數字格式**\n",
    "            fixed_text = fix_spacing_with_regex(text)\n",
    "\n",
    "            # **再修正單詞間距**\n",
    "            fixed_text = preserve_format(fixed_text)\n",
    "\n",
    "            print(f\"第 {i+1} 頁的文字（直接擷取 + 修正空格）：\\n{fixed_text}\")\n",
    "        else:  \n",
    "            # **如果無法解析，則使用 OCR**\n",
    "            image = pdf2image.convert_from_path(pdf_path, first_page=i+1, last_page=i+1)[0]\n",
    "            text = pytesseract.image_to_string(image, lang=\"eng\")\n",
    "\n",
    "            # **先修正標點與數字格式**\n",
    "            fixed_text = fix_spacing_with_regex(text)\n",
    "\n",
    "            # **再修正單詞間距**\n",
    "            fixed_text = preserve_format(fixed_text)\n",
    "\n",
    "            print(f\"第 {i+1} 頁的文字（OCR 擷取 + 修正空格）：\\n{fixed_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5458062-a830-428a-a753-2f34a99e6efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TalentLinker)",
   "language": "python",
   "name": "talentlinker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
