{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb7fb106-c1d7-4445-98c5-8619dda9a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬ 1 é çš„æ–‡å­—ï¼ˆç›´æ¥æ“·å–ï¼‰ï¼š\n",
      "Jou-Yi Lee\n",
      "65RioRoblesE,SanJose,CA95134â€¢zoelee19991226@gmail.comâ€¢+1408-618-9437â€¢+886978-716-05\n",
      "ABOUTME\n",
      "Aspiringcomputerscientistwithastrongbackgroundinengineeringandresearch,aimingtoleverageskillsinmachine\n",
      "learning,robotics,andsoftwaredevelopmentforinnovativeprojectsinnaturallanguageprocessing.\n",
      "SKILLS\n",
      "TechnicalSkills\n",
      "âœ“ ProgrammingLanguages: C++,Python,MATLAB\n",
      "âœ“ SoftwareandTools: PyTorch,Selenium,Scrapy,OpenCV,SolidWorks,AutoCAD,Ansys\n",
      "âœ“ MachineLearningandAI:PyTorch,TensorFlow,Scikit-learn,NLTK,SpaCy\n",
      "âœ“ EmbeddedSystems: RaspberryPi,Arduino\n",
      "âœ“ MechanicalDesign: 3DPrinting,PlasticandMetalPartsDesign\n",
      "SoftSkills\n",
      "âœ“ Self-drivenlearning,Innovation,Problem-solving,Communication\n",
      "RESEARCHPROJECTS\n",
      "FeatureEngineeringandModelEvaluationforE-commerce Sep2024-Nov2024\n",
      "Advisor: JalalMahmud,R&D\n",
      "âœ“ Optimizedclassifiersforsentimentanalysisandproductcategorization.\n",
      "RelationExtractionfromNaturalLanguage Sep2024-Nov2024\n",
      "Advisor: AmitaMisra,Amazon\n",
      "âœ“ Builtdeeplearningmodelsforrelationextractioninconversationallanguage.\n",
      "SlotTaggingforNaturalLanguage Sep2024-Nov2024\n",
      "Advisor: AmitaMisra,Amazon\n",
      "âœ“ DevelopedaPyTorch-basedslottaggingmodelforvirtualassistants.\n",
      "MobileRobotPathPlanningusingQ-Learning Feb2023-Sep2024\n",
      "Advisor: SYEDHUMAYOONSHAH,YuanZeUniversity\n",
      "âœ“ ImprovedstaticnavigationusingQ-Learningandobjectdetection(OpenCV,YOLOv9).\n",
      "MarineDebrisImageNetVisualRecognition Feb2023-Oct2023\n",
      "Advisor: Ching-LuehChang,YuanZeUniversity\n",
      "âœ“ Designedvisualrecognitionmodelsformarinedebrisidentification.\n",
      "DeterministicSublinear-TimeApproximationsforMetric1-MedianSelection Feb2022-July2023\n",
      "Advisor: Ching-LuehChang,YuanZeUniversity\n",
      "âœ“ Developedmetricapproximationsforscalabledataanalysis.\n",
      "EDUCATION\n",
      "MasterofScienceinNaturalLanguageProcessing Sep2024-Present\n",
      "UniversityofCalifornia,SantaCruz\n",
      "âœ“ CurrentlypursuinggraduatestudiesinNLP\n",
      "BachelorofScienceinEngineering Jul2019-Jun2024\n",
      "YuanZeUniversity,Taoyuan,Taiwan\n",
      "âœ“ Majors: MechanicalEngineering,ChemicalEngineeringandMaterialsScience,ComputerScience\n",
      "ExchangePrograminComputerScience Jun2023-Sep2023\n",
      "UniversityofCalifornia,Berkeley,USA\n",
      "âœ“ Participatedinasemester-longexchangeprogram\n",
      "ç¬¬ 2 é çš„æ–‡å­—ï¼ˆç›´æ¥æ“·å–ï¼‰ï¼š\n",
      "EXPERIENCE\n",
      "OperationsAssistant Feb2024-Aug2024\n",
      "HuanzhongCo.,Ltd.,TaoyuanCity,Taiwan\n",
      "âœ“ Streamlinedsupplychainandmaintenanceprocessesatafuelstation,ensuringregulatorycompliance\n",
      "âœ“ Assistedinretailoperations,includingstaffmanagementandinventorycontrol\n",
      "ACTIVITIESANDAWARDS\n",
      "âœ“ MarineDebrisImageNetVisualRecognitionChallenge,Judgesâ€™ShortlistAward,Oct2023\n",
      "âœ“ SecondRunner-Up,MakerCompetition,2019\n",
      "âœ“ Member,MakerClub,YuanZeUniversity\n",
      "âœ“ Member,BookClub,YuanZeUniversity\n",
      "NOTABLEPROJECTS\n",
      "RoboticsandMechanicalDesign\n",
      "âœ“ Bio-mimeticSpiderRobot,PitchingRobot,ColorSortingRobot\n",
      "DeepLearningandReinforcementLearning\n",
      "âœ“ ImplementedreinforcementlearningalgorithmsusingOpenAIGym(Taxi-v3)andActor-Critic\n",
      "âœ“ Developedamarinedebrissortingsystem,awardedinacompetition\n",
      "SoftwareDevelopmentandSimulation\n",
      "âœ“ FerrisWheelDesign,CandyCrushSimulation\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pdf2image\n",
    "import pytesseract\n",
    "\n",
    "pdf_path = \"Resume_UCSC.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for i, page in enumerate(pdf.pages):\n",
    "        text = page.extract_text()\n",
    "        if text:  # å¦‚æœèƒ½ç›´æ¥æå–æ–‡å­—\n",
    "            print(f\"ç¬¬ {i+1} é çš„æ–‡å­—ï¼ˆç›´æ¥æ“·å–ï¼‰ï¼š\\n{text}\")\n",
    "        else:  # å¦‚æœä¸èƒ½æå–æ–‡å­—ï¼Œå‰‡ä½¿ç”¨ OCR\n",
    "            image = pdf2image.convert_from_path(pdf_path, first_page=i+1, last_page=i+1)[0]\n",
    "            text = pytesseract.image_to_string(image, lang=\"eng\")\n",
    "            print(f\"ç¬¬ {i+1} é çš„æ–‡å­—ï¼ˆOCR æ“·å–ï¼‰ï¼š\\n{text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db66d316-8c6e-40cd-98d8-2f8c350496c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åµæ¸¬èªè¨€ï¼šzh-cn\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return lang\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "sample_text = \"ä½ å¥½ ?\"\n",
    "detected_lang = detect_language(sample_text)\n",
    "print(f\"åµæ¸¬èªè¨€ï¼š{detected_lang}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "642aa07c-44e0-46ba-9fc8-05ac30c472f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬ 1 é  - èªè¨€ï¼šenï¼ˆå…§åµŒæ–‡å­—ï¼‰\n",
      "ç¬¬ 2 é  - èªè¨€ï¼šenï¼ˆå…§åµŒæ–‡å­—ï¼‰\n",
      "\n",
      "ğŸ“ æœ€çµ‚ OCR è¼¸å‡ºï¼š\n",
      "Jou-Yi Lee  65Rio Robles E ,San Jose ,CA 95134 zoelee 19991226@gmail .com + 1408- 618- 9437 + 886978- 716- 05 ABOUTME Aspiringcomputerscientistwithastrongbackgroundinengineeringandresearch ,aimingtoleverageskillsinmachine learning ,robotics ,andsoftwaredevelopmentforinnovativeprojectsinnaturallanguageprocessing . SKILLS Technical Skills âœ“ Programming Languages: C++,Python ,MATLAB âœ“ Softwareand Tools: Py Torch ,Selenium ,Scrapy ,Open CV ,Solid Works ,Auto CAD ,Ansys âœ“ Machine Learningand AI:Py Torch ,Tensor Flow ,Scikit-learn ,NLTK ,Spa Cy âœ“ Embedded Systems: Raspberry Pi ,Arduino âœ“ Mechanical Design:  3DPrinting ,Plasticand Metal Parts Design Soft Skills âœ“ Self-drivenlearning ,Innovation ,Problem-solving ,Communication RESEARCHPROJECTS Feature Engineeringand Model Evaluationfor E-commerce Sep 2024-Nov 2024 Advisor: Jalal Mahmud ,R&D âœ“ Optimizedclassifiersforsentimentanalysisandproductcategorization . Relation Extractionfrom Natural Language Sep 2024-Nov 2024 Advisor: Amita Misra ,Amazon âœ“ Builtdeeplearningmodelsforrelationextractioninconversationallanguage . Slot Taggingfor Natural Language Sep 2024-Nov 2024 Advisor: Amita Misra ,Amazon âœ“ Developeda Py Torch-basedslottaggingmodelforvirtualassistants . Mobile Robot Path Planningusing Q-Learning Feb 2023-Sep 2024 Advisor: SYEDHUMAYOONSHAH ,Yuan Ze University âœ“ Improvedstaticnavigationusing Q-Learningandobjectdetection(Open CV ,YOLOv 9). Marine Debris Image Net Visual Recognition Feb 2023-Oct 2023 Advisor: Ching-Lueh Chang ,Yuan Ze University âœ“ Designedvisualrecognitionmodelsformarinedebrisidentification . Deterministic Sublinear-Time Approximationsfor Metric 1-Median Selection Feb 2022-July 2023 Advisor: Ching-Lueh Chang ,Yuan Ze University âœ“ Developedmetricapproximationsforscalabledataanalysis . EDUCATION Masterof Sciencein Natural Language Processing Sep 2024-Present Universityof California ,Santa Cruz âœ“ Currentlypursuinggraduatestudiesin NLP Bachelorof Sciencein Engineering Jul 2019-Jun 2024 Yuan Ze University ,Taoyuan ,Taiwan âœ“ Majors: Mechanical Engineering ,Chemical Engineeringand Materials Science ,Computer Science Exchange Programin Computer Science Jun 2023-Sep 2023 Universityof California ,Berkeley ,USA âœ“ Participatedinasemester-longexchangeprogram\n",
      "EXPERIENCE Operations Assistant Feb 2024-Aug 2024 Huanzhong Co .,Ltd .,Taoyuan City ,Taiwan âœ“ Streamlinedsupplychainandmaintenanceprocessesatafuelstation ,ensuringregulatorycompliance âœ“ Assistedinretailoperations ,includingstaffmanagementandinventorycontrol ACTIVITIESANDAWARDS âœ“ Marine Debris Image Net Visual Recognition Challenge ,Judgesâ€™Shortlist Award ,Oct 2023 âœ“ Second Runner-Up ,Maker Competition , 2019 âœ“ Member ,Maker Club ,Yuan Ze University âœ“ Member ,Book Club ,Yuan Ze University NOTABLEPROJECTS Roboticsand Mechanical Design âœ“ Bio-mimetic Spider Robot ,Pitching Robot ,Color Sorting Robot Deep Learningand Reinforcement Learning âœ“ Implementedreinforcementlearningalgorithmsusing Open AIGym(Taxi-v 3)and Actor-Critic âœ“ Developedamarinedebrissortingsystem ,awardedinacompetition Software Developmentand Simulation âœ“ Ferris Wheel Design ,Candy Crush Simulation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pdf2image\n",
    "import pytesseract\n",
    "import re\n",
    "from langdetect import detect\n",
    "from easyocr import Reader\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "\n",
    "# TrOCR æ¨¡å‹ï¼ˆæ‰‹å¯«è¾¨è­˜ï¼‰\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\", ignore_mismatched_sizes=True)\n",
    "\n",
    "# EasyOCRï¼ˆå–®ç¨è™•ç†ä¸åŒèªè¨€ï¼‰\n",
    "reader_chinese_tra = Reader(['ch_tra', 'en'])\n",
    "reader_chinese_sim = Reader(['ch_sim', 'en'])\n",
    "reader_japanese = Reader(['ja', 'en'])\n",
    "reader_korean = Reader(['ko', 'en'])\n",
    "reader_russian = Reader(['ru', 'en'])\n",
    "reader_arabic = Reader(['ar', 'en'])\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"åµæ¸¬èªè¨€\"\"\"\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "def easyocr_multilang(image):\n",
    "    \"\"\"ä½¿ç”¨ EasyOCRï¼Œå¼·åˆ¶åŠ å…¥å–®è©é–“è·\"\"\"\n",
    "    final_text = []\n",
    "    \n",
    "    def process_reader(reader, lang_name):\n",
    "        print(f\"æ­£åœ¨ä½¿ç”¨ {lang_name} OCR...\")\n",
    "        results = reader.readtext(image)\n",
    "        text = \" \".join([res[1] for res in results])  # å¼·åˆ¶åŠ å…¥ç©ºæ ¼\n",
    "        final_text.append(text)\n",
    "\n",
    "    process_reader(reader_chinese_tra, \"ç¹é«”ä¸­æ–‡\")\n",
    "    process_reader(reader_chinese_sim, \"ç°¡é«”ä¸­æ–‡\")\n",
    "    process_reader(reader_japanese, \"æ—¥æ–‡\")\n",
    "    process_reader(reader_korean, \"éŸ“æ–‡\")\n",
    "    process_reader(reader_russian, \"ä¿„æ–‡\")\n",
    "    process_reader(reader_arabic, \"é˜¿æ‹‰ä¼¯æ–‡\")\n",
    "\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "def fix_spacing(text):\n",
    "    \"\"\"è‡ªå‹•ä¿®æ­£æ²’æœ‰ç©ºæ ¼çš„å–®è©\"\"\"\n",
    "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)  # å°å¯« + å¤§å¯«ä¹‹é–“è£œä¸Šç©ºæ ¼\n",
    "    text = re.sub(r'(\\w)([,.!?])', r'\\1 \\2', text)  # å–®è©èˆ‡æ¨™é»ç¬¦è™Ÿä¹‹é–“åŠ å…¥ç©ºæ ¼\n",
    "    text = re.sub(r'(\\D)(\\d)', r'\\1 \\2', text)  # éæ•¸å­—+æ•¸å­—ä¹‹é–“åŠ å…¥ç©ºæ ¼\n",
    "    return text\n",
    "\n",
    "def ocr_pipeline(pdf_path):\n",
    "    \"\"\"OCR è™•ç†æµç¨‹\"\"\"\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            if text:  # âœ… å…§åµŒæ–‡å­—å¯ç›´æ¥æå–\n",
    "                text = text.replace(\"\\n\", \" \").replace(\"â€¢\", \" \")  # ä¿®æ­£ PDF å…§åµŒæ ¼å¼å•é¡Œ\n",
    "                detected_lang = detect_language(text)\n",
    "                print(f\"ç¬¬ {i+1} é  - èªè¨€ï¼š{detected_lang}ï¼ˆå…§åµŒæ–‡å­—ï¼‰\")\n",
    "                extracted_text += text + \"\\n\"\n",
    "            else:\n",
    "                # ğŸš€ PDF è½‰æ›ç‚ºåœ–ç‰‡\n",
    "                image = pdf2image.convert_from_path(pdf_path, first_page=i+1, last_page=i+1)[0]\n",
    "\n",
    "                # âœ… ä½¿ç”¨ Tesseract OCRï¼Œç¢ºä¿å–®è©ä¹‹é–“æœ‰é–“æ ¼\n",
    "                text_ocr = pytesseract.image_to_string(\n",
    "                    image, lang=\"eng+chi_tra+jpn+kor+ara+rus\",\n",
    "                    config=\"--oem 3 --psm 6 -c preserve_interword_spaces=1\"\n",
    "                )\n",
    "                detected_lang = detect_language(text_ocr)\n",
    "\n",
    "                # âœ… å¦‚æœ Tesseract OCR çµæœå¤ªçŸ­ï¼Œæ”¹ç”¨ EasyOCR\n",
    "                if len(text_ocr.strip()) < 10:\n",
    "                    text_easyocr = easyocr_multilang(image)\n",
    "                    detected_lang = detect_language(text_easyocr)\n",
    "                    text_ocr = text_easyocr\n",
    "\n",
    "                # âœ… å¦‚æœæ˜¯æ‰‹å¯«å­—æˆ–é›£è­˜åˆ¥å…§å®¹ï¼Œæ”¹ç”¨ TrOCR\n",
    "                if detected_lang in [\"en\", \"zh-cn\", \"zh-tw\", \"ja\"]:\n",
    "                    image = image.convert(\"RGB\")\n",
    "                    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "                    generated_ids = model.generate(pixel_values)\n",
    "                    text_trocr = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "                    text_ocr = text_trocr\n",
    "\n",
    "                print(f\"ç¬¬ {i+1} é  - èªè¨€ï¼š{detected_lang}\")\n",
    "                extracted_text += text_ocr + \"\\n\"\n",
    "\n",
    "    # ä¿®æ­£é–“éš”å•é¡Œ\n",
    "    extracted_text = fix_spacing(extracted_text)\n",
    "    return extracted_text\n",
    "\n",
    "# æ¸¬è©¦ OCR\n",
    "pdf_path = \"Resume_UCSC.pdf\"\n",
    "text_output = ocr_pipeline(pdf_path)\n",
    "\n",
    "print(\"\\nğŸ“ æœ€çµ‚ OCR è¼¸å‡ºï¼š\")\n",
    "print(text_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6b2712d-0939-47c3-913e-22666d55abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬ 1 é çš„æ–‡å­—ï¼ˆç›´æ¥æ“·å– + ä¿®æ­£ç©ºæ ¼ï¼‰ï¼š\n",
      "jouyilee65rioroblese san jose ca95134 zoelee19991226@gmail.com  +1408-618-9437  +886978-716 05 about me aspiring computer scientist with a strong background in engineering and research aiming to leverage skills in machine learning robotics and software development for innovative projects in natural language processing skills technical skills programming languages cpython matlab software and tools py torch selenium scrap y opencv solidworks autocad ansys machine learning and a ipy torch tensor flow sci kit learn nl tk spacy embedded systems raspberry pi arduino mechanical design 3d printing plastic and metal parts design soft skills self driven learning innovation problem solving communication research projects feature engineering and model evaluation for ecommerce sep2024nov2024 advisor jalal mahmud rd optimized classifiers for sentiment analysis and product categorization relation extraction from natural language sep2024nov2024 advisor amita misra amazon built deep learning models for relation extraction in conversational languages lot tagging for natural language sep2024nov2024 advisor amita misra amazon developed apy torch based slot tagging model for virtual assistants mobile robot path planning using q learning feb2023sep2024 advisors yedhumayoonshahyuanze university improved static navigation using q learning and object detection open cvyolov9 marine debris image net visual recognition feb2023oct2023 advisor chingluehchangyuanze university designed visual recognition models for marine debris identification deterministic sublinear time approximations for metric 1 median selection feb2022july2023 advisor chingluehchangyuanze university developed metric approximations for scalable data analysis education master of science in natural language processing sep2024 present university of california santa cruz currently pursuing graduate studies in nlp bachelor of science in engineering jul2019jun2024yuanze university taoyuan taiwan majors mechanical engineering chemical engineering and materials science computer science exchange program in computer science jun2023sep2023 university of california berkeley usa participated in a semester long exchange program\n",
      "ç¬¬ 2 é çš„æ–‡å­—ï¼ˆç›´æ¥æ“·å– + ä¿®æ­£ç©ºæ ¼ï¼‰ï¼š\n",
      "experience operations assistant feb 2024aug2024huanzhongco ltd taoyuan city taiwan streamlined supply chain and maintenance processes at a fuel station ensuring regulatory compliance assisted in retail operations including staff management and inventory control activities and awards marine debris image net visual recognition challenge judges shortlist award oct2023 second runner up maker competition 2019membermakerclubyuanz e university member book club yuan ze university notable projects robotics and mechanical design biomimetic spider robot pitching robot color sorting robot deep learning and reinforcement learning implemented reinforcement learning algorithms using open aigymtaxiv3 and actor critic developed a marine debris sorting system awarded in a competition software development and simulation ferris wheel design candy crush simulation\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pdf2image\n",
    "import pytesseract\n",
    "import re\n",
    "from wordsegment import load, segment\n",
    "\n",
    "# åŠ è¼‰ wordsegment çš„çµ±è¨ˆæ¨¡å‹\n",
    "load()\n",
    "\n",
    "def fix_spacing_with_regex(text):\n",
    "    \"\"\"ä½¿ç”¨ Regular Expression ä¿®æ­£æ¨™é»ã€æ•¸å­—èˆ‡æ–‡å­—æ ¼å¼ï¼ˆä¸å½±éŸ¿ Gmail & Phoneï¼‰\"\"\"\n",
    "    \n",
    "    # **å…ˆæ‰¾åˆ° Email å’Œé›»è©±è™Ÿç¢¼**\n",
    "    email_pattern = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
    "    phone_pattern = r'(\\+?\\d{1,4}[-.\\s]?\\d{2,4}[-.\\s]?\\d{3,4}[-.\\s]?\\d{3,4})'\n",
    "    \n",
    "    all_matches = []\n",
    "    for match in re.finditer(email_pattern, text):\n",
    "        all_matches.append((match.start(), match.end(), match.group()))\n",
    "    for match in re.finditer(phone_pattern, text):\n",
    "        all_matches.append((match.start(), match.end(), match.group()))\n",
    "    \n",
    "    all_matches.sort(key=lambda x: x[0])\n",
    "\n",
    "    fixed_parts = []\n",
    "    last_end = 0\n",
    "\n",
    "    for start, end, value in all_matches:\n",
    "        normal_text = text[last_end:start]\n",
    "        if normal_text.strip():  \n",
    "            # **ä¿®æ­£æ ¼å¼**\n",
    "            normal_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', normal_text)  \n",
    "            normal_text = re.sub(r'(\\w)([,.!?])', r'\\1 \\2', normal_text)  \n",
    "\n",
    "            # **æ ¸å¿ƒä¿®æ­£é»**\n",
    "            normal_text = re.sub(r'([a-zA-Z]+)(\\d+)([a-zA-Z]+)(\\d+)', r'\\1 \\2 \\3 \\4', normal_text)  # **è™•ç†ã€Œæ–‡å­—+æ•¸å­—+æ–‡å­—+æ•¸å­—ã€**\n",
    "            normal_text = re.sub(r'([a-zA-Z]+)(\\d+)', r'\\1 \\2', normal_text)  # **è™•ç†ã€Œæ–‡å­—+æ•¸å­—ã€**\n",
    "            normal_text = re.sub(r'(\\d+)([a-zA-Z]+)', r'\\1 \\2', normal_text)  # **è™•ç†ã€Œæ•¸å­—+æ–‡å­—ã€**\n",
    "            normal_text = re.sub(r'(\\D)(\\d)', r'\\1 \\2', normal_text)  # **è™•ç†ã€Œéæ•¸å­—+æ•¸å­—ã€**\n",
    "            normal_text = re.sub(r'(\\d)(\\D)', r'\\1 \\2', normal_text)  # **è™•ç†ã€Œæ•¸å­—+éæ•¸å­—ã€**\n",
    "\n",
    "            fixed_parts.append(normal_text)\n",
    "\n",
    "        # **ç›´æ¥æ·»åŠ åŸå§‹ Email å’Œ Phone**\n",
    "        fixed_parts.append(value)\n",
    "        last_end = end\n",
    "\n",
    "    if last_end < len(text):\n",
    "        remaining_text = text[last_end:]\n",
    "        remaining_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', remaining_text)  \n",
    "        remaining_text = re.sub(r'(\\w)([,.!?])', r'\\1 \\2', remaining_text)  \n",
    "\n",
    "        # **æ ¸å¿ƒä¿®æ­£é»**\n",
    "        remaining_text = re.sub(r'([a-zA-Z]+)(\\d+)([a-zA-Z]+)(\\d+)', r'\\1 \\2 \\3 \\4', remaining_text)  # **è™•ç†ã€Œæ–‡å­—+æ•¸å­—+æ–‡å­—+æ•¸å­—ã€**\n",
    "        remaining_text = re.sub(r'([a-zA-Z]+)(\\d+)', r'\\1 \\2', remaining_text)  # **è™•ç†ã€Œæ–‡å­—+æ•¸å­—ã€**\n",
    "        remaining_text = re.sub(r'(\\d+)([a-zA-Z]+)', r'\\1 \\2', remaining_text)  # **è™•ç†ã€Œæ•¸å­—+æ–‡å­—ã€**\n",
    "        remaining_text = re.sub(r'(\\D)(\\d)', r'\\1 \\2', remaining_text)  # **è™•ç†ã€Œéæ•¸å­—+æ•¸å­—ã€**\n",
    "        remaining_text = re.sub(r'(\\d)(\\D)', r'\\1 \\2', remaining_text)  # **è™•ç†ã€Œæ•¸å­—+éæ•¸å­—ã€**\n",
    "\n",
    "        fixed_parts.append(remaining_text)\n",
    "\n",
    "    return \" \".join(fixed_parts)\n",
    "\n",
    "\n",
    "def preserve_format(text):\n",
    "    \"\"\"ä¿ç•™ Gmail å’Œé›»è©±è™Ÿç¢¼ï¼Œå°å…¶ä»–éƒ¨åˆ†ä½¿ç”¨ wordsegment ä¿®æ­£å–®è©é–“è·\"\"\"\n",
    "    \n",
    "    # **æ›´åš´è¬¹çš„ Gmail å’Œé›»è©±è™Ÿç¢¼åŒ¹é…**\n",
    "    email_pattern = r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})'\n",
    "    phone_pattern = r'(\\+?\\d{1,4}[-.\\s]?\\d{2,4}[-.\\s]?\\d{3,4}[-.\\s]?\\d{3,4})'\n",
    "\n",
    "    # **å…ˆæ‰¾åˆ° Email å’Œé›»è©±è™Ÿç¢¼**\n",
    "    all_matches = []\n",
    "    \n",
    "    for match in re.finditer(email_pattern, text):\n",
    "        all_matches.append((match.start(), match.end(), match.group()))\n",
    "\n",
    "    for match in re.finditer(phone_pattern, text):\n",
    "        all_matches.append((match.start(), match.end(), match.group()))\n",
    "\n",
    "    # **ä¾ç…§å‡ºç¾é †åºæ’åº**\n",
    "    all_matches.sort(key=lambda x: x[0])\n",
    "\n",
    "    # **åˆ†å‰²æ–‡æœ¬ï¼Œç¢ºä¿ Email å’Œ Phone ä¸é€²å…¥ `wordsegment`**\n",
    "    segmented_parts = []\n",
    "    last_end = 0\n",
    "\n",
    "    for start, end, value in all_matches:\n",
    "        # å–å‡ºä¸Šæ¬¡åŒ¹é…å¾Œçš„æ™®é€šæ–‡å­—éƒ¨åˆ†ï¼Œä¸¦ç”¨ wordsegment è™•ç†\n",
    "        normal_text = text[last_end:start]\n",
    "        if normal_text.strip():  # é¿å…å¤šé¤˜çš„ç©ºç™½æ®µè½\n",
    "            segmented_parts.append(\" \".join(segment(normal_text)))\n",
    "\n",
    "        # ç›´æ¥æ·»åŠ åŸå§‹çš„ Email æˆ– Phoneï¼Œä¸åšä»»ä½•è™•ç†\n",
    "        segmented_parts.append(value)\n",
    "\n",
    "        last_end = end\n",
    "\n",
    "    # **è™•ç†æœ€å¾Œä¸€æ®µæ–‡å­—ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰**\n",
    "    if last_end < len(text):\n",
    "        remaining_text = text[last_end:]\n",
    "        segmented_parts.append(\" \".join(segment(remaining_text)))\n",
    "\n",
    "    # **çµ„åˆå›åŸå§‹æ–‡æœ¬**\n",
    "    return \" \".join(segmented_parts)\n",
    "\n",
    "pdf_path = \"Resume_UCSC.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for i, page in enumerate(pdf.pages):\n",
    "        text = page.extract_text()\n",
    "        if text:  \n",
    "            # **å…ˆä¿®æ­£æ¨™é»èˆ‡æ•¸å­—æ ¼å¼**\n",
    "            fixed_text = fix_spacing_with_regex(text)\n",
    "\n",
    "            # **å†ä¿®æ­£å–®è©é–“è·**\n",
    "            fixed_text = preserve_format(fixed_text)\n",
    "\n",
    "            print(f\"ç¬¬ {i+1} é çš„æ–‡å­—ï¼ˆç›´æ¥æ“·å– + ä¿®æ­£ç©ºæ ¼ï¼‰ï¼š\\n{fixed_text}\")\n",
    "        else:  \n",
    "            # **å¦‚æœç„¡æ³•è§£æï¼Œå‰‡ä½¿ç”¨ OCR**\n",
    "            image = pdf2image.convert_from_path(pdf_path, first_page=i+1, last_page=i+1)[0]\n",
    "            text = pytesseract.image_to_string(image, lang=\"eng\")\n",
    "\n",
    "            # **å…ˆä¿®æ­£æ¨™é»èˆ‡æ•¸å­—æ ¼å¼**\n",
    "            fixed_text = fix_spacing_with_regex(text)\n",
    "\n",
    "            # **å†ä¿®æ­£å–®è©é–“è·**\n",
    "            fixed_text = preserve_format(fixed_text)\n",
    "\n",
    "            print(f\"ç¬¬ {i+1} é çš„æ–‡å­—ï¼ˆOCR æ“·å– + ä¿®æ­£ç©ºæ ¼ï¼‰ï¼š\\n{fixed_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5458062-a830-428a-a753-2f34a99e6efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TalentLinker)",
   "language": "python",
   "name": "talentlinker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
