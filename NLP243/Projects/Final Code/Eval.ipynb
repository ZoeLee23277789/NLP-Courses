{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afed72-ca2c-478f-b090-a486493d3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jieba\n",
    "from transformers import MBartForConditionalGeneration, MBart50Tokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import OpenHowNet\n",
    "# 確保 Google Drive 已掛載\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# 加载 OpenHowNet\n",
    "hownet_dict = OpenHowNet.HowNetDict()\n",
    "hownet_dict.initialize_similarity_calculation()\n",
    "\n",
    "# 加载哈工大词林并构建同义词集合\n",
    "def load_cilin(file_path):\n",
    "    synonym_groups = []\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if \"=\" in line:\n",
    "                words = line.strip().split('=')[1].split()\n",
    "                synonym_groups.append(set(words))\n",
    "    return synonym_groups\n",
    "\n",
    "# 检查两个词是否为同义词，包含 OpenHowNet 语义相似度\n",
    "def are_synonyms(word1, word2, synonym_groups, threshold=0.7):\n",
    "    for group in synonym_groups:\n",
    "        if word1 in group and word2 in group:\n",
    "            return True\n",
    "    similarity = hownet_dict.calculate_word_similarity(word1, word2)\n",
    "    if similarity is not None and similarity >= threshold:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# 分词函数\n",
    "def tokenize(text):\n",
    "    return list(jieba.cut(text))\n",
    "\n",
    "# 计算对齐词数及对齐的词\n",
    "def calculate_alignment(trans_tokens, ref_tokens, synonym_groups):\n",
    "    aligned = []\n",
    "    ref_set = set(ref_tokens)\n",
    "    for token in trans_tokens:\n",
    "        if token in ref_set:\n",
    "            aligned.append(token)\n",
    "            ref_set.remove(token)\n",
    "        else:\n",
    "            for ref_token in ref_set:\n",
    "                if are_synonyms(token, ref_token, synonym_groups):\n",
    "                    aligned.append(token)\n",
    "                    ref_set.remove(ref_token)\n",
    "                    break\n",
    "    return len(aligned), aligned\n",
    "\n",
    "# 计算 Fragmentation Penalty\n",
    "def calculate_fragmentation(trans_tokens, aligned_tokens):\n",
    "    aligned_indices = [i for i, token in enumerate(trans_tokens) if token in aligned_tokens]\n",
    "    if not aligned_indices:\n",
    "        return 1.0\n",
    "    fragments = 1\n",
    "    for i in range(1, len(aligned_indices)):\n",
    "        if aligned_indices[i] != aligned_indices[i - 1] + 1:\n",
    "            fragments += 1\n",
    "    fragmentation_penalty = 0.5 * (fragments / len(aligned_indices))**3\n",
    "    return fragmentation_penalty\n",
    "\n",
    "# 计算 METEOR\n",
    "def calculate_meteor(trans_tokens, ref_tokens, synonym_groups):\n",
    "    aligned_count, aligned_tokens = calculate_alignment(trans_tokens, ref_tokens, synonym_groups)\n",
    "    precision = aligned_count / len(trans_tokens) if trans_tokens else 0\n",
    "    recall = aligned_count / len(ref_tokens) if ref_tokens else 0\n",
    "\n",
    "    alpha = 0.9\n",
    "    f_score = (precision * recall) / (alpha * precision + (1 - alpha) * recall) if precision + recall > 0 else 0\n",
    "    penalty = calculate_fragmentation(trans_tokens, aligned_tokens)\n",
    "    meteor = f_score * (1 - penalty)\n",
    "\n",
    "    return {\n",
    "        \"Aligned Tokens\": aligned_tokens,\n",
    "        \"Aligned Count\": aligned_count,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F-Score\": f_score,\n",
    "        \"Fragmentation Penalty\": penalty,\n",
    "        \"METEOR\": meteor,\n",
    "    }\n",
    "\n",
    "# 配置路径\n",
    "cilin_path = \"/content/cilin.txt\"  # 同义词词典路径\n",
    "config_folder = \"/content/drive/MyDrive/mbart_finetuned_dynamic_final_2\"\n",
    "weights_folder = \"/content/drive/MyDrive/mbart_finetuned_dynamic_updated_2/checkpoint-156105\"\n",
    "output_path = \"/content/drive/MyDrive/NER_Output/translated_results_iwslt_1127.json\"\n",
    "\n",
    "# 加载同义词词林\n",
    "synonym_groups = load_cilin(cilin_path)\n",
    "\n",
    "# 加载 IWSLT 数据集\n",
    "dataset = load_dataset(\"iwslt2017\", \"iwslt2017-en-zh\", split=\"test\")\n",
    "\n",
    "# 加载模型和 tokenizer\n",
    "model = MBartForConditionalGeneration.from_pretrained(weights_folder, config=config_folder).to(\"cuda\")\n",
    "tokenizer = MBart50Tokenizer.from_pretrained(config_folder)\n",
    "\n",
    "# 评估函数\n",
    "def evaluate_translations(model, tokenizer, dataset, output_path, synonym_groups, num_translations=5):\n",
    "    print(\"Starting evaluation...\")\n",
    "    translated_results = []\n",
    "    total_meteor = 0\n",
    "    total_bleu = 0\n",
    "    num_sentences = 0\n",
    "\n",
    "    for example in tqdm(dataset):\n",
    "        input_text = example[\"translation\"][\"en\"]\n",
    "        reference_text = tokenize(example[\"translation\"][\"zh\"])\n",
    "\n",
    "        # 模型生成多个翻译\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=256).to(\"cuda\")\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=256,\n",
    "            num_return_sequences=num_translations,\n",
    "            num_beams=num_translations,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        translations = [tokenize(tokenizer.decode(output, skip_special_tokens=True)) for output in outputs]\n",
    "\n",
    "        # 计算 METEOR 分数\n",
    "        meteor_scores = [\n",
    "            calculate_meteor(translation, reference_text, synonym_groups)[\"METEOR\"]\n",
    "            for translation in translations\n",
    "        ]\n",
    "\n",
    "        # 找到最佳翻译\n",
    "        best_translation_idx = max(range(len(meteor_scores)), key=lambda idx: meteor_scores[idx])\n",
    "        best_translation = translations[best_translation_idx]\n",
    "        best_meteor_score = meteor_scores[best_translation_idx]\n",
    "\n",
    "        # 计算 BLEU 分数\n",
    "        bleu_score = sentence_bleu([reference_text], best_translation)\n",
    "\n",
    "        # 累积分数\n",
    "        total_meteor += best_meteor_score\n",
    "        total_bleu += bleu_score\n",
    "        num_sentences += 1\n",
    "\n",
    "        translated_results.append({\n",
    "            \"Original Text\": input_text,\n",
    "            \"Reference Text\": \" \".join(reference_text),\n",
    "            \"All Translations\": [\" \".join(translation) for translation in translations],\n",
    "            \"Best Translation\": \" \".join(best_translation),\n",
    "            \"Best METEOR Score\": best_meteor_score,\n",
    "            \"BLEU Score\": bleu_score\n",
    "        })\n",
    "\n",
    "    # 保存结果\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(translated_results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # 输出总体分数\n",
    "    print(f\"Overall METEOR: {total_meteor / num_sentences}\")\n",
    "    print(f\"Overall BLEU: {total_bleu / num_sentences}\")\n",
    "    print(f\"Evaluation results saved to {output_path}\")\n",
    "\n",
    "# 执行评估\n",
    "evaluate_translations(model, tokenizer, dataset, output_path, synonym_groups, num_translations=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
