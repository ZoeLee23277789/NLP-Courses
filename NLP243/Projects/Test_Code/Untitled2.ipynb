{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401de5df-3cb8-4dbb-b4a7-cc717f35e7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nr', 'ns'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas to load and analyze the uploaded file\n",
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded CSV file to inspect the tags\n",
    "file_path = './Chience_iwslt20e17_ner_tagged.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract all unique tags from the \"Chinese NER Tagged\" column\n",
    "# Assuming the tags are in the format: [('Entity', 'Tag', start, end), ...]\n",
    "import ast\n",
    "\n",
    "# Initialize a set to store unique tags\n",
    "unique_tags = set()\n",
    "\n",
    "# Parse each entry in the \"Chinese NER Tagged\" column\n",
    "for tagged_data in df['Chinese NER Tagged']:\n",
    "    # Skip empty entries\n",
    "    if tagged_data and tagged_data != \"[]\":\n",
    "        # Convert string representation of list to actual list\n",
    "        entities = ast.literal_eval(tagged_data)\n",
    "        # Extract tags and add them to the set\n",
    "        for entity, tag, _, _ in entities:\n",
    "            unique_tags.add(tag)\n",
    "\n",
    "# Output all unique tags\n",
    "unique_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52af3863-bf1a-4b4c-b2b2-5a7e7cdea417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOCATION', 'MISC', 'O', 'ORGANIZATION', 'PERSON'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the newly uploaded file to inspect the English NER tags and extract all unique tags\n",
    "file_path_new = './Test_iwslt2017_ner_tagged.csv'\n",
    "df_new = pd.read_csv(file_path_new)\n",
    "\n",
    "# Initialize a set to store unique tags for English NER Tagged column\n",
    "unique_english_tags = set()\n",
    "\n",
    "# Parse each entry in the \"English NER Tagged\" column\n",
    "for tagged_data in df_new['English NER Tagged']:\n",
    "    # Skip empty entries\n",
    "    if tagged_data and tagged_data != \"[]\":\n",
    "        # Convert string representation of list to actual list\n",
    "        entities = ast.literal_eval(tagged_data)\n",
    "        # Extract tags and add them to the set\n",
    "        for _, tag in entities:\n",
    "            unique_english_tags.add(tag)\n",
    "\n",
    "# Output all unique English tags\n",
    "unique_english_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d2cf6f-aeb4-4a9a-b200-5c68554597ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Processing Chinese NER with HanLP: 100%|███████████████████████████████████████████| 2000/2000 [11:17<00:00,  2.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import hanlp\n",
    "\n",
    "# 載入 HanLP 模型\n",
    "hanlp_model = hanlp.load(hanlp.pretrained.mtl.CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH)\n",
    "\n",
    "# 使用 datasets 套件載入 IWSLT 2017 英中翻譯資料集，設置 trust_remote_code=True\n",
    "dataset = load_dataset('iwslt2017', 'iwslt2017-en-zh', split='train[:2000]', trust_remote_code=True)\n",
    "\n",
    "# 提取中文句子\n",
    "chinese_sentences = [example['translation']['zh'] for example in dataset]\n",
    "# print(\"chinese_sentences = \",chinese_sentences)\n",
    "# 進行中文命名實體識別使用 HanLP\n",
    "chinese_ner_results = []\n",
    "for sentence in tqdm(chinese_sentences, desc=\"Processing Chinese NER with HanLP\"):\n",
    "    tagged_words = hanlp_model(sentence)['ner/pku']\n",
    "    chinese_ner_results.append(tagged_words)\n",
    "\n",
    "# 將結果轉換為 DataFrame 便於檢視\n",
    "ner_df = pd.DataFrame({\n",
    "    \"Chinese Sentence\": chinese_sentences,\n",
    "    \"Chinese NER Tagged\": chinese_ner_results\n",
    "})\n",
    "\n",
    "# 保存 NER 標記結果到 CSV 文件\n",
    "ner_df.to_csv(r\"C:\\Users\\USER\\Downloads\\NLP-Courses\\NLP243\\Projects\\Chience_ner_tagged_2000.csv\", index=False, encoding='utf-8-sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27185c91-c939-45c7-b6d0-dae7891cddb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
