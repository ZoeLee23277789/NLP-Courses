{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19b7b776-2b79-4fa7-87ee-30a03cecd8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的設備: cpu\n",
      "        ID                                         utterances  \\\n",
      "0        1               who plays luke on star wars new hope   \n",
      "1        2                     show credits for the godfather   \n",
      "2        3             who was the main actor in the exorcist   \n",
      "3        4  find the female actress from the movie she 's ...   \n",
      "4        5                    who played dory on finding nemo   \n",
      "...    ...                                                ...   \n",
      "2307  2308               what was the revenue for toy story 3   \n",
      "2308  2309                                dark knight revenue   \n",
      "2309  2310               how much did the dark night generate   \n",
      "2310  2311                 can i see the lion king 's revenue   \n",
      "2311  2312        can i see what the lion king 's revenue was   \n",
      "\n",
      "                                      IOB Slot tags  \n",
      "0      O O B_char O B_movie I_movie I_movie I_movie  \n",
      "1                             O O O B_movie I_movie  \n",
      "2                       O O O O O O B_movie I_movie  \n",
      "3     O O O O O O O B_movie I_movie I_movie I_movie  \n",
      "4                      O O B_char O B_movie I_movie  \n",
      "...                                             ...  \n",
      "2307              O O O O O B_movie I_movie I_movie  \n",
      "2308                              B_movie I_movie O  \n",
      "2309                O O O B_movie I_movie I_movie O  \n",
      "2310              O O O B_movie I_movie I_movie O O  \n",
      "2311          O O O O B_movie I_movie I_movie O O O  \n",
      "\n",
      "[2312 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels padded shape: torch.Size([2312, 128])\n",
      "Epoch 1/10, Train Loss: 1.7926, Test Loss: 1.0691\n",
      "Epoch 2/10, Train Loss: 0.7987, Test Loss: 0.6648\n",
      "Epoch 3/10, Train Loss: 0.4944, Test Loss: 0.5183\n",
      "Epoch 4/10, Train Loss: 0.3511, Test Loss: 0.4474\n",
      "Epoch 5/10, Train Loss: 0.2493, Test Loss: 0.4068\n",
      "Epoch 6/10, Train Loss: 0.1879, Test Loss: 0.3916\n",
      "Epoch 7/10, Train Loss: 0.1455, Test Loss: 0.3882\n",
      "Epoch 8/10, Train Loss: 0.1225, Test Loss: 0.3616\n",
      "Epoch 9/10, Train Loss: 0.0898, Test Loss: 0.3688\n",
      "Epoch 10/10, Train Loss: 0.0732, Test Loss: 0.3705\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 檢查是否有 GPU 可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用的設備:\", device)\n",
    "\n",
    "# 加載數據\n",
    "train_df = pd.read_csv('hw2_train.csv')\n",
    "print(train_df)\n",
    "\n",
    "# 初始化 BERT Tokenizer 和 Model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "\n",
    "# 設定最大序列長度\n",
    "MAX_LENGTH = 128  # 可根據需要調整\n",
    "\n",
    "# 調整 BERT 編碼函數\n",
    "def encode_texts(texts, tokenizer, bert_model, device, max_length=MAX_LENGTH):\n",
    "    inputs = tokenizer(\n",
    "        texts, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    # 使用 BERT 的最後一層隱藏狀態作為嵌入表示\n",
    "    embeddings = outputs.last_hidden_state  # Shape: (batch_size, max_length, hidden_dim)\n",
    "    return embeddings, inputs[\"attention_mask\"].sum(dim=1)  # 返回序列長度以進行對比\n",
    "\n",
    "# 提取句子的 BERT 嵌入\n",
    "utterances = train_df['utterances'].tolist()\n",
    "embeddings, sequence_lengths = encode_texts(utterances, tokenizer, bert_model, device)\n",
    "\n",
    "# ======================== 新增的標籤處理部分 ========================\n",
    "# 構建標籤映射字典\n",
    "unique_labels = set(label for tags in train_df['IOB Slot tags'] for label in tags.split())\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "# 將標籤轉換為數字格式並填充到 BERT 輸出的 max_length 長度\n",
    "labels = train_df['IOB Slot tags'].apply(lambda x: [label_to_index[label] for label in x.split()])\n",
    "\n",
    "# 強制填充標籤到 BERT 輸出的長度（128）\n",
    "labels_padded = pad_sequence(\n",
    "    [torch.tensor(label + [label_to_index[\"O\"]] * (MAX_LENGTH - len(label))) for label in labels], \n",
    "    batch_first=True\n",
    ").to(device)\n",
    "\n",
    "# 打印標籤填充後的形狀以進行檢查\n",
    "print(f\"Labels padded shape: {labels_padded.shape}\")\n",
    "# ===============================================================\n",
    "\n",
    "# 最後確認 BERT 嵌入與標籤的形狀一致\n",
    "assert embeddings.shape[1] == labels_padded.shape[1], \"BERT 輸出序列長度和標籤序列長度不匹配\"\n",
    "# 分割訓練和測試數據\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels_padded, test_size=0.2, random_state=42)\n",
    "print\n",
    "# 創建數據集和數據加載器\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 定義 LSTM 模型來處理 BERT 輸出\n",
    "class SlotTaggingModel(nn.Module):\n",
    "    def __init__(self, bert_hidden_dim, hidden_dim, output_dim):\n",
    "        super(SlotTaggingModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(bert_hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "# 初始化模型\n",
    "bert_hidden_dim = embeddings.shape[2]  # BERT 隱藏層的輸出維度\n",
    "hidden_dim = 128  # LSTM 隱藏層的維度\n",
    "output_dim = len(label_to_index)  # 標籤數量\n",
    "model = SlotTaggingModel(bert_hidden_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=label_to_index[\"O\"])  # 忽略填充標籤\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 訓練模型\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        # 檢查輸入和標籤的形狀\n",
    "        assert batch_x.shape[1] == batch_y.shape[1], \"輸出序列長度和標籤序列長度不匹配\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x).view(-1, output_dim)  # (batch_size * seq_len, output_dim)\n",
    "        batch_y = batch_y.view(-1)  # (batch_size * seq_len)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# 評估模型\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            \n",
    "            # 檢查輸入和標籤的形狀\n",
    "            assert batch_x.shape[1] == batch_y.shape[1], \"輸出序列長度和標籤序列長度不匹配\"\n",
    "\n",
    "            outputs = model(batch_x).view(-1, output_dim)\n",
    "            batch_y = batch_y.view(-1)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)\n",
    "\n",
    "# 訓練和評估過程\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss = evaluate_model(model, test_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b792a9-0132-418d-a6de-16821b04ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的設備: cpu\n",
      "        ID                                         utterances  \\\n",
      "0        1               who plays luke on star wars new hope   \n",
      "1        2                     show credits for the godfather   \n",
      "2        3             who was the main actor in the exorcist   \n",
      "3        4  find the female actress from the movie she 's ...   \n",
      "4        5                    who played dory on finding nemo   \n",
      "...    ...                                                ...   \n",
      "2307  2308               what was the revenue for toy story 3   \n",
      "2308  2309                                dark knight revenue   \n",
      "2309  2310               how much did the dark night generate   \n",
      "2310  2311                 can i see the lion king 's revenue   \n",
      "2311  2312        can i see what the lion king 's revenue was   \n",
      "\n",
      "                                      IOB Slot tags  \n",
      "0      O O B_char O B_movie I_movie I_movie I_movie  \n",
      "1                             O O O B_movie I_movie  \n",
      "2                       O O O O O O B_movie I_movie  \n",
      "3     O O O O O O O B_movie I_movie I_movie I_movie  \n",
      "4                      O O B_char O B_movie I_movie  \n",
      "...                                             ...  \n",
      "2307              O O O O O B_movie I_movie I_movie  \n",
      "2308                              B_movie I_movie O  \n",
      "2309                O O O B_movie I_movie I_movie O  \n",
      "2310              O O O B_movie I_movie I_movie O O  \n",
      "2311          O O O O B_movie I_movie I_movie O O O  \n",
      "\n",
      "[2312 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_subject seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_movie seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_director seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_director seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_movie seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_mpaa_rating seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_producer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_cast seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_cast seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_person seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_person seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_subject seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_producer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_country seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_language seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_language seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_genre seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_char seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_genre seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_mpaa_rating seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0489\n",
      "Precision: 0.0019, Recall: 0.2286, F1 Score: 0.0038\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.02      0.11      0.03        18\n",
      "       _char       0.00      0.00      0.00         1\n",
      "    _country       0.00      0.83      0.01        23\n",
      "   _director       0.00      0.09      0.00        32\n",
      "      _genre       0.50      0.08      0.13        13\n",
      "   _language       0.01      0.60      0.02        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.13      0.00       217\n",
      "_mpaa_rating       0.01      0.78      0.02        32\n",
      "     _person       0.01      0.13      0.02        39\n",
      "   _producer       0.01      0.05      0.02        38\n",
      "    _subject       0.01      0.33      0.02        21\n",
      "\n",
      "   micro avg       0.00      0.23      0.00       455\n",
      "   macro avg       0.05      0.26      0.02       455\n",
      "weighted avg       0.02      0.23      0.01       455\n",
      "\n",
      "Epoch 1/10, Train Loss: 1.8051, Test Loss: 1.0489\n",
      "Test Loss: 0.6589\n",
      "Precision: 0.0019, Recall: 0.1978, F1 Score: 0.0038\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.00      0.00      0.00        18\n",
      "       _char       0.00      0.00      0.00         1\n",
      "    _country       0.00      0.78      0.01        23\n",
      "   _director       0.00      0.16      0.00        32\n",
      "      _genre       0.08      0.31      0.12        13\n",
      "   _language       0.01      0.70      0.02        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.06      0.00       217\n",
      "_mpaa_rating       0.01      0.78      0.02        32\n",
      "     _person       0.01      0.10      0.01        39\n",
      "   _producer       0.00      0.03      0.00        38\n",
      "    _subject       0.00      0.33      0.01        21\n",
      "\n",
      "   micro avg       0.00      0.20      0.00       455\n",
      "   macro avg       0.01      0.27      0.02       455\n",
      "weighted avg       0.00      0.20      0.01       455\n",
      "\n",
      "Epoch 2/10, Train Loss: 0.8000, Test Loss: 0.6589\n",
      "Test Loss: 0.5101\n",
      "Precision: 0.0022, Recall: 0.2176, F1 Score: 0.0043\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.00      0.00      0.00        18\n",
      "       _char       1.00      1.00      1.00         1\n",
      "    _country       0.00      0.96      0.01        23\n",
      "   _director       0.00      0.06      0.00        32\n",
      "      _genre       0.05      0.38      0.09        13\n",
      "   _language       0.01      0.75      0.02        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.07      0.00       217\n",
      "_mpaa_rating       0.01      0.81      0.01        32\n",
      "     _person       0.00      0.08      0.00        39\n",
      "   _producer       0.00      0.05      0.00        38\n",
      "    _subject       0.00      0.38      0.00        21\n",
      "\n",
      "   micro avg       0.00      0.22      0.00       455\n",
      "   macro avg       0.09      0.38      0.10       455\n",
      "weighted avg       0.01      0.22      0.01       455\n",
      "\n",
      "Epoch 3/10, Train Loss: 0.4964, Test Loss: 0.5101\n",
      "Test Loss: 0.4498\n",
      "Precision: 0.0021, Recall: 0.2242, F1 Score: 0.0041\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.00      0.00      0.00        18\n",
      "       _char       0.50      1.00      0.67         1\n",
      "    _country       0.01      0.87      0.02        23\n",
      "   _director       0.00      0.03      0.00        32\n",
      "      _genre       0.01      0.38      0.02        13\n",
      "   _language       0.00      0.85      0.01        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.11      0.00       217\n",
      "_mpaa_rating       0.00      0.78      0.01        32\n",
      "     _person       0.00      0.08      0.00        39\n",
      "   _producer       0.00      0.03      0.00        38\n",
      "    _subject       0.00      0.29      0.01        21\n",
      "\n",
      "   micro avg       0.00      0.22      0.00       455\n",
      "   macro avg       0.04      0.37      0.06       455\n",
      "weighted avg       0.00      0.22      0.01       455\n",
      "\n",
      "Epoch 4/10, Train Loss: 0.3472, Test Loss: 0.4498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_country seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4121\n",
      "Precision: 0.0020, Recall: 0.2132, F1 Score: 0.0040\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.00      0.00      0.00        18\n",
      "       _char       0.33      1.00      0.50         1\n",
      "    _country       0.01      0.91      0.01        23\n",
      "   _director       0.00      0.06      0.00        32\n",
      "      _genre       0.01      0.38      0.02        13\n",
      "   _language       0.00      0.60      0.01        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.10      0.00       217\n",
      "_mpaa_rating       0.00      0.75      0.01        32\n",
      "     _person       0.00      0.10      0.01        39\n",
      "   _producer       0.00      0.03      0.00        38\n",
      "    _subject       0.00      0.29      0.01        21\n",
      "\n",
      "   micro avg       0.00      0.21      0.00       455\n",
      "   macro avg       0.03      0.35      0.05       455\n",
      "weighted avg       0.00      0.21      0.00       455\n",
      "\n",
      "Epoch 5/10, Train Loss: 0.2563, Test Loss: 0.4121\n",
      "Test Loss: 0.3888\n",
      "Precision: 0.0017, Recall: 0.1780, F1 Score: 0.0034\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.00      0.06      0.00        18\n",
      "       _char       0.20      1.00      0.33         1\n",
      "    _country       0.01      0.91      0.01        23\n",
      "   _director       0.00      0.03      0.00        32\n",
      "      _genre       0.01      0.54      0.01        13\n",
      "   _language       0.00      0.40      0.00        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.06      0.00       217\n",
      "_mpaa_rating       0.00      0.56      0.01        32\n",
      "     _person       0.00      0.08      0.00        39\n",
      "   _producer       0.00      0.08      0.00        38\n",
      "    _subject       0.00      0.19      0.00        21\n",
      "\n",
      "   micro avg       0.00      0.18      0.00       455\n",
      "   macro avg       0.02      0.33      0.03       455\n",
      "weighted avg       0.00      0.18      0.00       455\n",
      "\n",
      "Epoch 6/10, Train Loss: 0.1925, Test Loss: 0.3888\n",
      "Test Loss: 0.3850\n",
      "Precision: 0.0019, Recall: 0.2022, F1 Score: 0.0039\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.00      0.00      0.00        18\n",
      "       _char       0.25      1.00      0.40         1\n",
      "    _country       0.01      0.91      0.02        23\n",
      "   _director       0.00      0.03      0.00        32\n",
      "      _genre       0.00      0.62      0.01        13\n",
      "   _language       0.00      0.40      0.00        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.10      0.00       217\n",
      "_mpaa_rating       0.00      0.62      0.01        32\n",
      "     _person       0.00      0.05      0.00        39\n",
      "   _producer       0.00      0.13      0.00        38\n",
      "    _subject       0.00      0.19      0.00        21\n",
      "\n",
      "   micro avg       0.00      0.20      0.00       455\n",
      "   macro avg       0.02      0.34      0.04       455\n",
      "weighted avg       0.00      0.20      0.00       455\n",
      "\n",
      "Epoch 7/10, Train Loss: 0.1489, Test Loss: 0.3850\n",
      "Test Loss: 0.3734\n",
      "Precision: 0.0018, Recall: 0.1890, F1 Score: 0.0036\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.00      0.00      0.00        18\n",
      "       _char       0.17      1.00      0.29         1\n",
      "    _country       0.02      0.87      0.03        23\n",
      "   _director       0.00      0.03      0.00        32\n",
      "      _genre       0.00      0.46      0.01        13\n",
      "   _language       0.00      0.45      0.00        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.10      0.00       217\n",
      "_mpaa_rating       0.00      0.53      0.01        32\n",
      "     _person       0.00      0.03      0.00        39\n",
      "   _producer       0.00      0.11      0.00        38\n",
      "    _subject       0.00      0.24      0.00        21\n",
      "\n",
      "   micro avg       0.00      0.19      0.00       455\n",
      "   macro avg       0.02      0.32      0.03       455\n",
      "weighted avg       0.00      0.19      0.00       455\n",
      "\n",
      "Epoch 8/10, Train Loss: 0.1234, Test Loss: 0.3734\n",
      "Test Loss: 0.3539\n",
      "Precision: 0.0018, Recall: 0.1758, F1 Score: 0.0035\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.00      0.00      0.00        18\n",
      "       _char       0.11      1.00      0.20         1\n",
      "    _country       0.02      0.87      0.03        23\n",
      "   _director       0.00      0.00      0.00        32\n",
      "      _genre       0.00      0.54      0.01        13\n",
      "   _language       0.00      0.35      0.00        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.08      0.00       217\n",
      "_mpaa_rating       0.00      0.59      0.01        32\n",
      "     _person       0.00      0.03      0.00        39\n",
      "   _producer       0.00      0.08      0.00        38\n",
      "    _subject       0.00      0.19      0.00        21\n",
      "\n",
      "   micro avg       0.00      0.18      0.00       455\n",
      "   macro avg       0.01      0.31      0.02       455\n",
      "weighted avg       0.00      0.18      0.00       455\n",
      "\n",
      "Epoch 9/10, Train Loss: 0.0934, Test Loss: 0.3539\n",
      "Test Loss: 0.3518\n",
      "Precision: 0.0019, Recall: 0.1868, F1 Score: 0.0038\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       _cast       0.00      0.06      0.00        18\n",
      "       _char       0.17      1.00      0.29         1\n",
      "    _country       0.02      0.87      0.03        23\n",
      "   _director       0.00      0.03      0.00        32\n",
      "      _genre       0.00      0.54      0.01        13\n",
      "   _language       0.00      0.40      0.00        20\n",
      "   _location       0.00      0.00      0.00         1\n",
      "      _movie       0.00      0.10      0.00       217\n",
      "_mpaa_rating       0.00      0.59      0.01        32\n",
      "     _person       0.00      0.03      0.00        39\n",
      "   _producer       0.00      0.03      0.00        38\n",
      "    _subject       0.00      0.24      0.01        21\n",
      "\n",
      "   micro avg       0.00      0.19      0.00       455\n",
      "   macro avg       0.02      0.32      0.03       455\n",
      "weighted avg       0.00      0.19      0.00       455\n",
      "\n",
      "Epoch 10/10, Train Loss: 0.0723, Test Loss: 0.3518\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "# 檢查是否有 GPU 可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用的設備:\", device)\n",
    "\n",
    "# 加載數據\n",
    "train_df = pd.read_csv('hw2_train.csv')\n",
    "print(train_df)\n",
    "\n",
    "# 初始化 BERT Tokenizer 和 Model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "\n",
    "# 設定最大序列長度\n",
    "MAX_LENGTH = 128  # 可根據需要調整\n",
    "\n",
    "# 調整 BERT 編碼函數\n",
    "def encode_texts(texts, tokenizer, bert_model, device, max_length=MAX_LENGTH):\n",
    "    inputs = tokenizer(\n",
    "        texts, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state  # Shape: (batch_size, max_length, hidden_dim)\n",
    "    return embeddings, inputs[\"attention_mask\"].sum(dim=1)\n",
    "\n",
    "# 提取句子的 BERT 嵌入\n",
    "utterances = train_df['utterances'].tolist()\n",
    "embeddings, sequence_lengths = encode_texts(utterances, tokenizer, bert_model, device)\n",
    "\n",
    "# 構建標籤映射字典\n",
    "unique_labels = set(label for tags in train_df['IOB Slot tags'] for label in tags.split())\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_index.items()}\n",
    "\n",
    "# 將標籤轉換為數字格式並填充到 BERT 輸出的 max_length 長度\n",
    "labels = train_df['IOB Slot tags'].apply(lambda x: [label_to_index[label] for label in x.split()])\n",
    "labels_padded = pad_sequence(\n",
    "    [torch.tensor(label + [label_to_index[\"O\"]] * (MAX_LENGTH - len(label))) for label in labels], \n",
    "    batch_first=True\n",
    ").to(device)\n",
    "\n",
    "# 最後確認 BERT 嵌入與標籤的形狀一致\n",
    "assert embeddings.shape[1] == labels_padded.shape[1], \"BERT 輸出序列長度和標籤序列長度不匹配\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels_padded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 創建數據集和數據加載器\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 定義 LSTM 模型來處理 BERT 輸出\n",
    "class SlotTaggingModel(nn.Module):\n",
    "    def __init__(self, bert_hidden_dim, hidden_dim, output_dim):\n",
    "        super(SlotTaggingModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(bert_hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.fc(lstm_out)\n",
    "        return output\n",
    "\n",
    "# 初始化模型\n",
    "bert_hidden_dim = embeddings.shape[2]\n",
    "hidden_dim = 128\n",
    "output_dim = len(label_to_index)\n",
    "model = SlotTaggingModel(bert_hidden_dim, hidden_dim, output_dim).to(device)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=label_to_index[\"O\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 訓練模型\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        assert batch_x.shape[1] == batch_y.shape[1], \"輸出序列長度和標籤序列長度不匹配\"\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x).view(-1, output_dim)\n",
    "        batch_y = batch_y.view(-1)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# 調整後的評估模型\n",
    "def evaluate_model(model, test_loader, criterion, device, idx_to_label):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            assert batch_x.shape[1] == batch_y.shape[1], \"輸出序列長度和標籤序列長度不匹配\"\n",
    "\n",
    "            outputs = model(batch_x).view(-1, output_dim)\n",
    "            batch_y = batch_y.view(-1)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            labels = batch_y.cpu().numpy()\n",
    "\n",
    "            # 將 index 轉換為對應的標籤\n",
    "            preds = [idx_to_label[idx] for idx in preds]\n",
    "            labels = [idx_to_label[idx] for idx in labels]\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    \n",
    "    # 使用 seqeval 計算精確度、召回率和 F1 分數\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    return avg_loss, precision, recall, f1\n",
    "\n",
    "# 訓練和評估過程\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, precision, recall, f1 = evaluate_model(model, test_loader, criterion, device, idx_to_label)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0300fb0-9ea9-493d-b2be-1f32c598a644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提交文件已生成：submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# 假設已經定義和訓練好的模型 SlotTaggingModel\n",
    "# 載入測試數據\n",
    "test_df = pd.read_csv('hw2_test.csv')\n",
    "\n",
    "# 定義生成提交文件的函數\n",
    "def generate_submission_file(model, test_df, tokenizer, bert_model, idx_to_label, device, output_file=\"submission.csv\"):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in test_df.iterrows():\n",
    "            utterance = row[\"utterances\"]\n",
    "            \n",
    "            # 1. 使用 BERT 將句子轉換為嵌入\n",
    "            inputs = tokenizer(utterance, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\").to(device)\n",
    "            embeddings = bert_model(**inputs).last_hidden_state  # 取得 BERT 最後一層的輸出 (batch_size, seq_len, hidden_dim)\n",
    "            \n",
    "            # 2. 使用模型進行預測\n",
    "            outputs = model(embeddings)  # 確認這裡的輸出是 (batch_size, seq_len, output_dim)\n",
    "            \n",
    "            # 3. 確保 outputs 的維度符合預期\n",
    "            if outputs.dim() == 2:  # 當輸出只有 (seq_len, output_dim) 時進行擴展\n",
    "                outputs = outputs.unsqueeze(0)  # 增加 batch 維度\n",
    "\n",
    "            # 4. 獲取每個位置的預測標籤\n",
    "            pred_labels = torch.argmax(outputs, dim=2).squeeze().cpu().numpy()\n",
    "            pred_labels = [idx_to_label[label] for label in pred_labels[:len(inputs['input_ids'][0])]]\n",
    "\n",
    "            # 5. 將子詞標籤整合成單詞標籤\n",
    "            tokens = tokenizer.tokenize(utterance)\n",
    "            final_labels = []\n",
    "            token_idx = 0\n",
    "\n",
    "            for label in pred_labels:\n",
    "                if token_idx >= len(tokens):\n",
    "                    break  # 防止 token_idx 超出 tokens 的長度\n",
    "                \n",
    "                # 跳過以 \"##\" 開頭的子詞標籤\n",
    "                if tokens[token_idx].startswith(\"##\"):\n",
    "                    token_idx += 1\n",
    "                    continue\n",
    "                \n",
    "                final_labels.append(label)\n",
    "                token_idx += 1\n",
    "\n",
    "            # 6. 加入預測結果\n",
    "            predictions.append(\" \".join(final_labels))\n",
    "\n",
    "    # 建立提交文件格式\n",
    "    submission_df = pd.DataFrame({\"ID\": test_df[\"ID\"], \"IOB Slot Tags\": predictions})\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"提交文件已生成：{output_file}\")\n",
    "\n",
    "# 構建標籤映射字典\n",
    "unique_labels = set(label for tags in train_df['IOB Slot tags'] for label in tags.split())\n",
    "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "idx_to_label = {idx: label for label, idx in label_to_index.items()}\n",
    "\n",
    "# 生成提交文件\n",
    "generate_submission_file(model, test_df, tokenizer, bert_model, idx_to_label, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
