{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb2c5b2-cf7e-487e-b469-20f0e33af2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的設備: cuda\n",
      "   ID                                         UTTERANCES  \\\n",
      "0   0               who plays luke on star wars new hope   \n",
      "1   1                     show credits for the godfather   \n",
      "2   2             who was the main actor in the exorcist   \n",
      "3   3  find the female actress from the movie she's t...   \n",
      "4   4                    who played dory on finding nemo   \n",
      "\n",
      "                                     CORE RELATIONS  \n",
      "0  [movie.starring.actor, movie.starring.character]  \n",
      "1                            [movie.starring.actor]  \n",
      "2                            [movie.starring.actor]  \n",
      "3              [movie.starring.actor, actor.gender]  \n",
      "4  [movie.starring.actor, movie.starring.character]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # 用於設置 NaN 值\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 檢查是否有 GPU 可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用的設備:\", device)\n",
    "\n",
    "# path\n",
    "train_file_path = r\"C:\\Users\\USER\\Downloads\\NLP-Courses\\NLP243\\Assignments\\HW1_Relation Extraction from Natural Language using PyTorch\\hw1_train-1.csv\"\n",
    "\n",
    "# Load the file\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "\n",
    "# Fill up the Nan to \"\"\n",
    "train_df['CORE RELATIONS'] = train_df['CORE RELATIONS'].fillna('')\n",
    "\n",
    "# strings into lists\n",
    "train_df['CORE RELATIONS'] = train_df['CORE RELATIONS'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46397a8-f047-4f3c-b362-dd0f21541561",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(max_features=1000)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(2312, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Init the BOW，max_features == 1000\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "print(vectorizer)\n",
    "# UTTERANCES to array\n",
    "X_train = vectorizer.fit_transform(train_df['UTTERANCES']).toarray()\n",
    "print(X_train)\n",
    "# print the shape\n",
    "# [[0 0 0 ... 0 0 0]\n",
    "#  [0 0 0 ... 0 0 0]\n",
    "#  [0 0 0 ... 0 0 0]\n",
    "#  ...\n",
    "#  [0 0 0 ... 0 0 0]\n",
    "#  [0 0 0 ... 0 0 0]\n",
    "#  [0 0 0 ... 0 0 0]]\n",
    "print(X_train.shape)  #  (sample, features)(2312, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f379cafd-fb90-4651-93c7-35cbda6d06d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2312, 19)\n",
      "['actor.gender' 'gr.amount' 'movie.country' 'movie.directed_by'\n",
      " 'movie.estimated_budget' 'movie.genre' 'movie.gross_revenue'\n",
      " 'movie.initial_release_date' 'movie.language' 'movie.locations'\n",
      " 'movie.music' 'movie.produced_by' 'movie.production_companies'\n",
      " 'movie.rating' 'movie.starring.actor' 'movie.starring.character'\n",
      " 'movie.subjects' 'none' 'person.date_of_birth']\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer() # have mult-label\n",
    "\n",
    "y_train = mlb.fit_transform(train_df['CORE RELATIONS']) # label to num arr\n",
    "\n",
    "print(y_train.shape)  # output = (sample , total label)\n",
    "print(mlb.classes_)    # label class name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff5f490-a176-46c8-a33a-cb347edba92f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1849, 1000) (463, 1000)\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# the size of the dataset\n",
    "print(X_train.shape, X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631c2c77-6ccd-4491-b806-28568a13ec1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data -> PyTorch vector -> move to GPU\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2c65353-29ab-4641-99ae-2e18ff322df3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class MLPRelationModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLPRelationModel, self).__init__()\n",
    "        self.Layer1 = nn.Linear(input_dim, 256)  # 更新隱藏層大小為 256\n",
    "        self.Layer2 = nn.Linear(256, 128)        # 更新隱藏層大小為 128\n",
    "        self.Layer3 = nn.Linear(128, output_dim) # 保持輸出層\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.Layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.Layer2(x))\n",
    "        x = self.Layer3(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(mlb.classes_)\n",
    "\n",
    "# 初始化模型並使用最佳學習率\n",
    "model = MLPRelationModel(input_dim, output_dim).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 使用多標籤損失函數\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0027414732532805475)  # 更新學習率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81e23b4-8c1f-474b-bbd5-5891a5c4f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2921549354133935\n",
      "Epoch 2, Loss: 0.16121013963530803\n",
      "Epoch 3, Loss: 0.08543155753406985\n",
      "Epoch 4, Loss: 0.048322935652887\n",
      "Epoch 5, Loss: 0.03140673012440574\n",
      "Epoch 6, Loss: 0.02215408447102226\n",
      "Epoch 7, Loss: 0.017137798890150314\n",
      "Epoch 8, Loss: 0.013702522357122908\n",
      "Epoch 9, Loss: 0.011387516587876297\n",
      "Epoch 10, Loss: 0.009739683220435962\n",
      "Epoch 11, Loss: 0.009051516688236132\n",
      "Epoch 12, Loss: 0.007960107970324442\n",
      "Epoch 13, Loss: 0.006100722696985407\n",
      "Epoch 14, Loss: 0.006755752729830043\n",
      "Epoch 15, Loss: 0.005715074808465253\n",
      "Epoch 16, Loss: 0.004543171860357939\n",
      "Epoch 17, Loss: 0.004158171169772937\n",
      "Epoch 18, Loss: 0.0033961943112883783\n",
      "Epoch 19, Loss: 0.0034995958583373256\n",
      "Epoch 20, Loss: 0.003071722577291878\n",
      "Epoch 21, Loss: 0.0026913560030716955\n",
      "Epoch 22, Loss: 0.0032618538037962118\n",
      "Epoch 23, Loss: 0.002927982298544897\n",
      "Epoch 24, Loss: 0.0030129072316601104\n",
      "Epoch 25, Loss: 0.0027421722326584257\n",
      "Epoch 26, Loss: 0.0025525194793991775\n",
      "Epoch 27, Loss: 0.002443808639484281\n",
      "Epoch 28, Loss: 0.0024588175397968434\n",
      "Epoch 29, Loss: 0.0018721709533690892\n",
      "Epoch 30, Loss: 0.002163174533303265\n",
      "Epoch 31, Loss: 0.0023929817951535244\n",
      "Epoch 32, Loss: 0.0023005301110719427\n",
      "Epoch 33, Loss: 0.0014022596407248158\n",
      "Epoch 34, Loss: 0.0015813430937073306\n",
      "Epoch 35, Loss: 0.0020709213146393925\n",
      "Epoch 36, Loss: 0.0013550898419108024\n",
      "Epoch 37, Loss: 0.0013945012869326407\n",
      "Epoch 38, Loss: 0.0017622367580268725\n",
      "Epoch 39, Loss: 0.0012681651655996043\n",
      "Epoch 40, Loss: 0.0009568384922549112\n",
      "Epoch 41, Loss: 0.001223725849772093\n",
      "Epoch 42, Loss: 0.0012054894017135918\n",
      "Epoch 43, Loss: 0.000808849233839408\n",
      "Epoch 44, Loss: 0.0015182022787735934\n",
      "Epoch 45, Loss: 0.0012931103559790714\n",
      "Epoch 46, Loss: 0.0011746043743689118\n",
      "Epoch 47, Loss: 0.001198162077281299\n",
      "Epoch 48, Loss: 0.001181201636537198\n",
      "Epoch 49, Loss: 0.002191531151954129\n",
      "Epoch 50, Loss: 0.0009016656259236384\n",
      "Epoch 51, Loss: 0.001031820231626876\n",
      "Epoch 52, Loss: 0.0008256790842379218\n",
      "Epoch 53, Loss: 0.0011396580009816184\n",
      "Epoch 54, Loss: 0.0009886767805036124\n",
      "Epoch 55, Loss: 0.0021196967622456905\n",
      "Epoch 56, Loss: 0.002052469311475479\n",
      "Epoch 57, Loss: 0.0013069749290072399\n",
      "Epoch 58, Loss: 0.001429912133532745\n",
      "Epoch 59, Loss: 0.0010369437506189318\n",
      "Epoch 60, Loss: 0.0013998174707263262\n",
      "Epoch 61, Loss: 0.0013059553630541656\n",
      "Epoch 62, Loss: 0.0008819400554157568\n",
      "Epoch 63, Loss: 0.0011147775889310588\n",
      "Epoch 64, Loss: 0.0008972645315256598\n",
      "Epoch 65, Loss: 0.0009178112023336922\n",
      "Epoch 66, Loss: 0.0006627017536284884\n",
      "Epoch 67, Loss: 0.0010091703974592684\n",
      "Epoch 68, Loss: 0.0009373622451832865\n",
      "Epoch 69, Loss: 0.001218095745876969\n",
      "Epoch 70, Loss: 0.001090214212910786\n",
      "Epoch 71, Loss: 0.001911617148019512\n",
      "Epoch 72, Loss: 0.0019046636389718735\n",
      "Epoch 73, Loss: 0.0010317976388846703\n",
      "Epoch 74, Loss: 0.0010783347345295624\n",
      "Epoch 75, Loss: 0.0006276168976455665\n",
      "Epoch 76, Loss: 0.0008100405823331035\n",
      "Epoch 77, Loss: 0.0008894214872803975\n",
      "Epoch 78, Loss: 0.0010957904964455118\n",
      "Epoch 79, Loss: 0.0007971766715713627\n",
      "Epoch 80, Loss: 0.0011596237742541517\n",
      "Epoch 81, Loss: 0.001647704946149447\n",
      "Epoch 82, Loss: 0.0011256494564710511\n",
      "Epoch 83, Loss: 0.0008476230385393388\n",
      "Epoch 84, Loss: 0.001106050699087095\n",
      "Epoch 85, Loss: 0.0013007184209308088\n",
      "Epoch 86, Loss: 0.0012981055030556082\n",
      "Epoch 87, Loss: 0.0017761957027342477\n",
      "Epoch 88, Loss: 0.0012402315651970325\n",
      "Epoch 89, Loss: 0.000924671779055894\n",
      "Epoch 90, Loss: 0.0007209377220392368\n",
      "Epoch 91, Loss: 0.0013730844995718833\n",
      "Epoch 92, Loss: 0.0009663829548571812\n",
      "Epoch 93, Loss: 0.001738423841876785\n",
      "Epoch 94, Loss: 0.0013517031774865935\n",
      "Epoch 95, Loss: 0.0013804171643649733\n",
      "Epoch 96, Loss: 0.0006901740406929407\n",
      "Epoch 97, Loss: 0.0009547379093042953\n",
      "Epoch 98, Loss: 0.0012961529312492373\n",
      "Epoch 99, Loss: 0.0010330831644609886\n",
      "Epoch 100, Loss: 0.00045673224976075413\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "for epoch in range(100):  # 更新為最佳 epoch 數量\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}, Loss: {avg_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84d6ae81-06e0-4ab7-a977-03c138f93499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提交文件已成功生成，無法預測的行填充為 'none'！\n"
     ]
    }
   ],
   "source": [
    "# 讀取測試數據\n",
    "test_file_path = r\"C:\\Users\\USER\\Downloads\\NLP-Courses\\NLP243\\Assignments\\HW1_Relation Extraction from Natural Language using PyTorch\\hw1_test-2.csv\"\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "X_test = vectorizer.transform(test_df['UTTERANCES']).toarray()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# 使用模型進行預測\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "    predicted = (torch.sigmoid(outputs) > 0.5).float().cpu()\n",
    "\n",
    "# 將預測結果轉換為原始標籤格式\n",
    "predicted_relations = mlb.inverse_transform(predicted.numpy())\n",
    "\n",
    "# 生成提交文件\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'CORE RELATIONS': ['none' if len(relations) == 0 else ' '.join(relations) for relations in predicted_relations]\n",
    "})\n",
    "\n",
    "# 保存提交文件\n",
    "submission_df.to_csv('Final_submission.csv', index=False)\n",
    "print(\"提交文件已成功生成，無法預測的行填充為 'none'！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845d58e-7d79-4a96-875f-d27b30373542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
