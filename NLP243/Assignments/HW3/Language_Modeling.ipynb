{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "501bc95d-183c-403f-821d-3904829d17cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "ptb= load_dataset('ptb_text_only', split=['train', 'validation', 'test'], trust_remote_code=True)\n",
    "\n",
    "# 1. 建立詞彙表\n",
    "def build_vocab(sentences, min_freq=2):\n",
    "    # 計算詞頻\n",
    "    counter = Counter()\n",
    "    for sentence in sentences:\n",
    "        tokens = re.findall(r'\\w+', sentence.lower())  # 將句子轉換為小寫並用正則表達式分詞\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    # 建立詞彙表，僅保留頻率大於等於 min_freq 的詞\n",
    "    vocab = {word: idx for idx, (word, count) in enumerate(counter.items(), start=2) if count >= min_freq}\n",
    "    \n",
    "    # 添加特殊符號 (e.g., PAD for padding, UNK for unknown tokens)\n",
    "    vocab['<PAD>'] = 0\n",
    "    vocab['<UNK>'] = 1\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "# 2. 將句子格式化為詞彙索引\n",
    "def format_sentences(sentences, vocab):\n",
    "    formatted_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = re.findall(r'\\w+', sentence.lower())\n",
    "        # 使用詞彙表將詞轉換為索引\n",
    "        indexed_sentence = [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "        formatted_sentences.append(indexed_sentence)\n",
    "    return formatted_sentences\n",
    "\n",
    "# 將資料集中的句子提取出來\n",
    "train_sentences = [example['sentence'] for example in ptb[0]]\n",
    "validation_sentences = [example['sentence'] for example in ptb[1]]\n",
    "test_sentences = [example['sentence'] for example in ptb[2]]\n",
    "\n",
    "# 建立詞彙表 (基於訓練集)\n",
    "vocab = build_vocab(train_sentences)\n",
    "\n",
    "# 格式化句子\n",
    "train_data = format_sentences(train_sentences, vocab)\n",
    "validation_data = format_sentences(validation_sentences, vocab)\n",
    "test_data = format_sentences(test_sentences, vocab)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # 將每個數據點的句子解包，因為 DataLoader 傳遞過來的是一個列表，列表中的每個元素是 TensorDataset 中的一個元組\n",
    "    sentences = [item[0] for item in batch]\n",
    "    # 使用 pad_sequence 將句子填充為相同長度\n",
    "    padded_batch = pad_sequence(sentences, batch_first=True, padding_value=vocab['<PAD>'])\n",
    "    return padded_batch\n",
    "\n",
    "# 重新定義 DataLoader，這次使用修正的 collate_fn\n",
    "batch_size = 32\n",
    "\n",
    "# 使用 TensorDataset 包裝數據\n",
    "train_dataset = TensorDataset(torch.nn.utils.rnn.pad_sequence(train_tensors, batch_first=True, padding_value=vocab['<PAD>']))\n",
    "validation_dataset = TensorDataset(torch.nn.utils.rnn.pad_sequence(validation_tensors, batch_first=True, padding_value=vocab['<PAD>']))\n",
    "test_dataset = TensorDataset(torch.nn.utils.rnn.pad_sequence(test_tensors, batch_first=True, padding_value=vocab['<PAD>']))\n",
    "\n",
    "# 定義 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46075e0b-95c3-4cbf-bb91-a0dec424d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 建立詞彙表\n",
    "def build_vocab(sentences, min_freq=2):\n",
    "    # 計算詞頻\n",
    "    counter = Counter()\n",
    "    for sentence in sentences:\n",
    "        tokens = re.findall(r'\\w+', sentence.lower())  # 將句子轉換為小寫並用正則表達式分詞\n",
    "        counter.update(tokens)\n",
    "    \n",
    "    # 建立詞彙表，僅保留頻率大於等於 min_freq 的詞\n",
    "    vocab = {word: idx for idx, (word, count) in enumerate(counter.items(), start=2) if count >= min_freq}\n",
    "    \n",
    "    # 添加特殊符號 (e.g., PAD for padding, UNK for unknown tokens)\n",
    "    vocab['<PAD>'] = 0\n",
    "    vocab['<UNK>'] = 1\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "# 2. 將句子格式化為詞彙索引\n",
    "def format_sentences(sentences, vocab):\n",
    "    formatted_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = re.findall(r'\\w+', sentence.lower())\n",
    "        # 使用詞彙表將詞轉換為索引\n",
    "        indexed_sentence = [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
    "        formatted_sentences.append(indexed_sentence)\n",
    "    return formatted_sentences\n",
    "\n",
    "# 將資料集中的句子提取出來\n",
    "train_sentences = [example['sentence'] for example in ptb[0]]\n",
    "validation_sentences = [example['sentence'] for example in ptb[1]]\n",
    "test_sentences = [example['sentence'] for example in ptb[2]]\n",
    "\n",
    "# 建立詞彙表 (基於訓練集)\n",
    "vocab = build_vocab(train_sentences)\n",
    "\n",
    "# 格式化句子\n",
    "train_data = format_sentences(train_sentences, vocab)\n",
    "validation_data = format_sentences(validation_sentences, vocab)\n",
    "test_data = format_sentences(test_sentences, vocab)\n",
    "\n",
    "# 確認處理後的數據\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "print(f\"First 3 training examples (as word indices): {train_data[:3]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
